<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ロボットシステム入門</title><link>https://matsuolab.github.io/roomba_hack_course/</link><atom:link href="https://matsuolab.github.io/roomba_hack_course/index.xml" rel="self" type="application/rss+xml"/><description>ロボットシステム入門</description><generator>Wowchemy (https://wowchemy.com)</generator><language>ja</language><copyright>© 2023 Tokyo Robot And Intelligence Lab (TRAIL)</copyright><lastBuildDate>Thu, 22 Jun 2023 00:00:00 +0000</lastBuildDate><image><url>https://matsuolab.github.io/roomba_hack_course/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url><title>ロボットシステム入門</title><link>https://matsuolab.github.io/roomba_hack_course/</link></image><item><title>ロボットシステムにおけるセンシング・アクチュエーション・通信②</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap3/sensing2/</link><pubDate>Thu, 22 Jun 2023 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap3/sensing2/</guid><description>&lt;p>複数のセンサを組み合わせてよりかしこくロボットを動かしてみよう&lt;/p>
&lt;h2 id="learn">Learn&lt;/h2>
&lt;p>前回使用した&lt;a href="https://github.com/matsuolab/roomba_hack/blob/master/catkin_ws/src/navigation_tutorial/scripts/simple_control.py" target="_blank" rel="noopener">simple_control.py&lt;/a>
では，速度，角速度，時間を指定し，
&amp;ldquo;速度 * 時間&amp;rdquo; あるいは &amp;ldquo;角速度 * 時間&amp;rdquo; という演算を行うことで，
ロボットを意図した場所へ移動させる命令を与えていました．&lt;/p>
&lt;p>しかし，この制御の仕方には，いくつかの問題があります．&lt;/p>
&lt;ul>
&lt;li>ホイールと地面との間に滑りがあった場合，ロボットは指定した距離より小さい距離しか移動しない可能性がある．&lt;/li>
&lt;li>ロボット本体の問題で，指定した速度よりも実際の速度が大きいまたは小さい場合，
ロボットは指定した位置には移動しない可能性がある．&lt;/li>
&lt;/ul>
&lt;p>これらは，動作の結果を考慮せず，はじめに指定した速度と時間にのみ従って動く，という制御の仕方のために起こります．&lt;/p>
&lt;p>このように，あらかじめ指定された制御信号にのみ基づいて制御を行い，
その結果（フィードバック情報）を考慮しない制御の仕方を
&lt;mark>フィードフォワード制御&lt;/mark>（開ループ制御）と呼びます．
フィードフォワード制御は，制御対象が予測可能で外乱が少ない場合や，
システムが簡潔である場合に使用されることがあります．&lt;/p>
&lt;p>一方で，センサーからのフィードバック情報を利用して制御信号を修正する制御の仕方を
&lt;mark>フィードバック制御&lt;/mark>（閉ループ制御）と呼びます．
フィードバック制御は，制御対象の予測が難しく，外乱が大きい場合に有効です．&lt;/p>
&lt;p>今回は，ロボットのセンサ情報を用いるフィードバック制御
によってロボットをより柔軟に動かしてみましょう．
オドメトリとLiDARという2種類のセンサの情報を用います．&lt;/p>
&lt;!--
前回の演習のようにロボットに速度と時間を一回与えて，その通りに動かすようなフィードフォワード制御ではなく，今回は，ロボットが逐次的にセンサの情報を反映して振る舞いを変える&lt;mark>フィードバック制御&lt;/mark>を行なってみましょう．-->
&lt;h3 id="オドメトリのセンサ情報を用いた制御">オドメトリのセンサ情報を用いた制御&lt;/h3>
&lt;p>まずは，ロボットのタイヤの回転量から計算される移動距離である&lt;mark>（ホイール）オドメトリ（odometry）&lt;/mark>を使った制御をしてみましょう．&lt;/p>
&lt;h4 id="オドメトリのメッセージodomの中身を見てみよう">オドメトリのメッセージ（&lt;code>/odom&lt;/code>）の中身を見てみよう&lt;/h4>
&lt;p>roombaのオドメトリの情報は，&lt;code>/odom&lt;/code>トピックにpublishされています．&lt;/p>
&lt;pre>&lt;code>$ rostopic echo /odom
&lt;/code>&lt;/pre>
&lt;p>を実行するとメッセージとしてどのような情報が流れているかがわかります．
&lt;details class="spoiler " id="spoiler-4">
&lt;summary>&lt;code>$ rostopic echo -n 1 /odom&lt;/code>&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-bash">root@dynamics:~/roomba_hack# rostopic echo -n 1 /odom
header:
seq: 2115
stamp:
secs: 1649692132
nsecs: 791056254
frame_id: &amp;quot;odom&amp;quot;
child_frame_id: &amp;quot;base_footprint&amp;quot;
pose:
pose:
position:
x: -0.014664691872894764
y: -0.0010878229513764381
z: 0.0
orientation:
x: 0.0
y: 0.0
z: 0.0056752621080531414
w: 0.9999838955703261
covariance: [0.08313143998384476, 0.00019857974257320166, 0.0, 0.0, 0.0, 0.004368376452475786, 0.00019857988809235394, 0.015032557770609856, 0.0, 0.0, 0.0, -0.26573312282562256, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0043683769181370735, -0.26573312282562256, 0.0, 0.0, 0.0, 6.021446704864502]
twist:
twist:
linear:
x: 0.0
y: 0.0
z: 0.0
angular:
x: 0.0
y: 0.0
z: 0.0
covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
---
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>&lt;/p>
&lt;p>また，&lt;/p>
&lt;pre>&lt;code>$ rostopic type /odom
&lt;/code>&lt;/pre>
&lt;p>を実行すると，メッセージとして，&lt;code>nav_msgs/Odometry&lt;/code>型が使われていることがわかります．
&lt;details class="spoiler " id="spoiler-5">
&lt;summary>&lt;code>$ rostopic type /odom&lt;/code>&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-bash">root@dynamics:~/roomba_hack# rostopic type /odom
nav_msgs/Odometry
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>&lt;/p>
&lt;p>&lt;a href="http://docs.ros.org/en/noetic/api/nav_msgs/html/msg/Odometry.html" target="_blank" rel="noopener">nav_msgs/Odometry型のドキュメント&lt;/a>を確認すると，このメッセージは&lt;code>pose&lt;/code>と&lt;code>twist&lt;/code>で構成されていることがわかります．&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>pose&lt;/code>は（&lt;code>child_frame&lt;/code>から見た）ロボットの推定姿勢（位置と回転角）を表していて，&lt;code>covariance&lt;/code>にはその不確かさを表す共分散が記録されています．&lt;/p>
&lt;/li>
&lt;li>
&lt;p>一方，&lt;code>twist&lt;/code>は（&lt;code>child_frame&lt;/code>から見た）ロボットの速度を表していて，&lt;code>pose&lt;/code>と同様に&lt;code>covariance&lt;/code>にはその不確かさを表す共分散が記録されています．&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>なお，メッセージ型の定義は，コマンドで&lt;/p>
&lt;pre>&lt;code>$ rosmsg info nav_msgs/Odometry
&lt;/code>&lt;/pre>
&lt;p>を実行しても確認できます．
&lt;details class="spoiler " id="spoiler-6">
&lt;summary>&lt;code>$ rosmsg info nav_msgs/Odometry&lt;/code>&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-bash">root@dynamics:~/roomba_hack# rosmsg info nav_msgs/Odometry
std_msgs/Header header
uint32 seq
time stamp
string frame_id
string child_frame_id
geometry_msgs/PoseWithCovariance pose
geometry_msgs/Pose pose
geometry_msgs/Point position
float64 x
float64 y
float64 z
geometry_msgs/Quaternion orientation
float64 x
float64 y
float64 z
float64 w
float64[36] covariance
geometry_msgs/TwistWithCovariance twist
geometry_msgs/Twist twist
geometry_msgs/Vector3 linear
float64 x
float64 y
float64 z
geometry_msgs/Vector3 angular
float64 x
float64 y
float64 z
float64[36] covariance
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>&lt;/p>
&lt;h4 id="クォータニオンquaternion">クォータニオン(quaternion)&lt;/h4>
&lt;p>さて，&lt;code>/odom&lt;/code>のトピックでは，ロボットの回転角は&lt;mark>クォータニオン（quaternion）&lt;/mark>で記述されています．&lt;/p>
&lt;p>クォータニオンは，日本語では四元数と呼ばれ，3次元空間上での回転角を表現する方法の一つで，4つの要素を持つベクトルで表現されます．&lt;/p>
&lt;p>クォータニオンによる3次元回転の表現は，角度を連続的にかつ簡潔に表現できるためROSではよく用いられます（その他には，オイラー角による表現や回転行列による表現があります）．&lt;/p>
&lt;p>それぞれの回転角に関する表現のメリット・デメリットを調べてみましょう（「ジンバルロック」などのキーワードで調べるとよりよく理解できると思います）．&lt;/p>
&lt;p>クォータニオンからオイラー角へは，&lt;code>tf&lt;/code>パッケージの&lt;code>tf.transformations.euler_from_quaternion&lt;/code>を使うことで変換できます（&lt;a href="http://docs.ros.org/en/jade/api/tf/html/python/transformations.html#tf.transformations.euler_from_quaternion" target="_blank" rel="noopener">ドキュメント&lt;/a>）．&lt;/p>
&lt;h4 id="実装の例を見てみる">実装の例を見てみる&lt;/h4>
&lt;p>それでは，オドメトリ&lt;code>/odom&lt;/code>の情報を使った制御の実装の例として&lt;code>navigation_tutorial&lt;/code>パッケージの中の&lt;code>simple_control2.py&lt;/code>を見てみましょう（&lt;a href="https://github.com/matsuolab/roomba_hack/blob/master/catkin_ws/src/navigation_tutorial/scripts/simple_control2.py" target="_blank" rel="noopener">github&lt;/a>）．&lt;/p>
&lt;h3 id="ソースコードを読んでみよう">ソースコードを読んでみよう&lt;/h3>
&lt;p>画面にウィンドウを2つ並べるなど，&lt;a href="https://github.com/matsuolab/roomba_hack/blob/master/catkin_ws/src/navigation_tutorial/scripts/simple_control2.py" target="_blank" rel="noopener">githubのソースコード&lt;/a>をみながら以下の解説を読むことをお勧めします．&lt;/p>
&lt;details class="spoiler " id="spoiler-8">
&lt;summary>simple_control2.py&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-python">#!/usr/bin/env python3
import numpy as np
import rospy
import tf
from geometry_msgs.msg import Twist
from nav_msgs.msg import Odometry
class SimpleController:
def __init__(self):
rospy.init_node('simple_controller', anonymous=True)
# Publisher
self.cmd_vel_pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)
# Subscriber
odom_sub = rospy.Subscriber('/odom', Odometry, self.callback_odom)
self.x = None
self.y = None
self.yaw = None
while self.x is None:
rospy.sleep(0.1)
def callback_odom(self, data):
self.x = data.pose.pose.position.x
self.y = data.pose.pose.position.y
self.yaw = self.get_yaw_from_quaternion(data.pose.pose.orientation)
def go_straight(self, dis, velocity=0.3):
vel = Twist()
x0 = self.x
y0 = self.y
while(np.sqrt((self.x-x0)**2+(self.y-y0)**2)&amp;lt;dis):
vel.linear.x = velocity
vel.angular.z = 0.0
self.cmd_vel_pub.publish(vel)
rospy.sleep(0.1)
self.stop()
def turn_right(self, yaw, yawrate=-0.5):
vel = Twist()
yaw0 = self.yaw
while(abs(self.yaw-yaw0)&amp;lt;np.deg2rad(yaw)):
vel.linear.x = 0.0
vel.angular.z = yawrate
self.cmd_vel_pub.publish(vel)
rospy.sleep(0.1)
self.stop()
def turn_left(self, yaw, yawrate=0.5):
vel = Twist()
yaw0 = self.yaw
while(abs(self.yaw-yaw0)&amp;lt;np.deg2rad(yaw)):
vel.linear.x = 0.0
vel.angular.z = yawrate
self.cmd_vel_pub.publish(vel)
rospy.sleep(0.1)
self.stop()
def stop(self):
vel = Twist()
vel.linear.x = 0.0
vel.angular.z = 0.0
self.cmd_vel_pub.publish(vel)
def get_yaw_from_quaternion(self, quaternion):
e = tf.transformations.euler_from_quaternion(
(quaternion.x, quaternion.y, quaternion.z, quaternion.w))
return e[2]
if __name__=='__main__':
simple_controller = SimpleController()
try:
simple_controller.go_straight(1.0)
simple_controller.turn_left(90)
simple_controller.turn_right(90)
except rospy.ROSInitException:
pass
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;h4 id="かんたんな説明">かんたんな説明&lt;/h4>
&lt;p>上記ソースコードの大枠のみを抜き出すと，以下のようになっています．
&lt;details class="spoiler " id="spoiler-9">
&lt;summary>simple_control2.pyの大枠&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-python">#!/usr/bin/env python3 # 1
import ~ # 2
class SimpleController: # 3
def __init__(self): # 4
pass
def callback_odom(self, data): # 5
pass
def go_straight(self, dis, velocity=0.3):
pass
def turn_right(self, yaw, yawrate=-0.5):
pass
def turn_left(self, yaw, yawrate=0.5):
pass
def stop(self):
pass
def get_yaw_from_quaternion(self, quaternion):
pass
if __name__=='__main__': # 6
simple_controller = SimpleController() # 7
pass
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>&lt;/p>
&lt;p>それぞれについて簡潔に解説します．&lt;/p>
&lt;details class="spoiler " id="spoiler-10">
&lt;summary>#1 shebang&lt;/summary>
&lt;p>shebang(シバン)と呼ばれるもので，このファイルを実行する際に，どのプログラムを使って実行するかを指定する．
&lt;code>#!/usr/bin/env python3&lt;/code> と書いてあるので，このファイルはpython3で実行するのだとコンピュータに教えている．&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-11">
&lt;summary>#2 import&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-python">import numpy as np
import rospy
import tf
from geometry_msgs.msg import Twist
from nav_msgs.msg import Odometry
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>pythonの標準の関数(printなど)だけでは機能が足りないので，別のモジュールをインポートしている．&lt;/li>
&lt;li>このソースコードでは，numpy, rospy, tf というモジュールをインポートしている．
&lt;ul>
&lt;li>rospyというのが，pythonでrosを使うためのモジュール．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>また，geometry_msgs.msgというモジュールからTwistというデータ型, nav_msgs.msgというモジュールからOdometoryというデータ型をそれぞれインポートしている．&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-12">
&lt;summary>#3 class&lt;/summary>
&lt;p>&lt;ul>
&lt;li>SimpleControllerという名前のクラスを定義している．&lt;/li>
&lt;li>クラスはオブジェクトの設計図のようなもの．
&lt;ul>
&lt;li>オブジェクトとは，データとそのデータの振る舞いをまとめたもの．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;details class="spoiler " id="spoiler-0">
&lt;summary>classの例1&lt;/summary>
&lt;p>&lt;p>以下のようなクラスを定義したとする．&lt;/p>
&lt;pre>&lt;code class="language-python">class Car:
def __init__(self, color, speed):
self.color = color
self.speed = speed
self.fuel = 100
&lt;p>def drive(self):
self.fuel -= 20
print(&amp;lsquo;drove!')
print(f&amp;rsquo;残りの燃料は{self.fuel}リットルです&amp;rsquo;)&lt;/p>
&lt;p>def charge(self):
self.fuel = 100
print(&amp;lsquo;charged!')
print(f&amp;rsquo;残りの燃料は{self.fuel}リットルです&amp;rsquo;)&lt;/p>
&lt;p>def info(self):
print(f&amp;rsquo;色は{self.color}です')
print(f&amp;rsquo;速度は{self.speed}km/hです')
print(f&amp;rsquo;残りの燃料は{self.fuel}リットルです')
&lt;/code>&lt;/pre>&lt;/p>
&lt;p>以下のように使える．&lt;/p>
&lt;pre>&lt;code class="language-python">mycar = Car('red', 200)
&lt;p>mycar.drive()
#drove!
#残りの燃料は80リットルです&lt;/p>
&lt;p>mycar.drive()
#drove!
#残りの燃料は60リットルです&lt;/p>
&lt;p>mycar.charge()
#charged!
#残りの燃料は100リットルです&lt;/p>
&lt;p>mycar.info()
#色はredです
#速度は200km/hです
#残りの燃料は100リットルです
&lt;/code>&lt;/pre>&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-1">
&lt;summary>classの例2&lt;/summary>
&lt;p>&lt;p>pythonのstring型や，int型，list型も，実はオブジェクトである．&lt;/p>
&lt;pre>&lt;code class="language-python">people = ['Alice', 'Bob', 'Charlie']
people.append('Dave')
&lt;p>print(people)
#[&amp;lsquo;Alice&amp;rsquo;, &amp;lsquo;Bob&amp;rsquo;, &amp;lsquo;Charlie&amp;rsquo;, &amp;lsquo;Dave&amp;rsquo;]
&lt;/code>&lt;/pre>&lt;/p>
&lt;p>上の例では，list型のオブジェクトpeopleに対して，appendというメソッド(そのオブジェクトが持つ関数)を呼び出し，新しい要素を追加している．&lt;/p>
&lt;/p>
&lt;/details>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-13">
&lt;summary>#4 コンストラクタ&lt;/summary>
&lt;p>&lt;ul>
&lt;li>コンストラクタ__init__()とは，オブジェクト生成時に呼び出される関数のこと．&lt;/li>
&lt;li>初期化のための関数というイメージ．&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-14">
&lt;summary>#5 メソッドの定義&lt;/summary>
&lt;p>&lt;ul>
&lt;li>メソッドとは，オブジェクトが持つ関数のこと．&lt;/li>
&lt;li>classの定義の中では，&lt;code>self.method_name(引数1, 引数2)&lt;/code>という形で呼び出すことができる．&lt;/li>
&lt;li>オブジェクトの外から使用するときには，上のCarの例のように，&lt;code>object_name.method_name(引数1, 引数2)&lt;/code>という形で呼び出すことができる．&lt;/li>
&lt;li>定義の第一引数には，必ず&lt;code>self&lt;/code>を指定する．これは，そのオブジェクト自身を指す．
&lt;ul>
&lt;li>呼び出すときには&lt;code>self&lt;/code>は省略する．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-15">
&lt;summary>#6 ファイル実行時の処理&lt;/summary>
&lt;p>&lt;ul>
&lt;li>このif文の中の処理は，ファイルを直接実行したときにのみ実行される．&lt;/li>
&lt;li>&lt;code>__name__&lt;/code>は特殊な変数で，ファイルを直接実行したときには&lt;code>'__main__'&lt;/code>という値を持つ．
&lt;ul>
&lt;li>importされたときには&lt;code>__name__&lt;/code>にはファイル名が入るため，このif文の中の処理は実行されない．
&lt;pre>&lt;code class="language-python">#!/usr/bin/env python3
print(__name__)
&lt;/code>&lt;/pre>
&lt;p>とだけ記述したファイルを実行してみると，ふるまいが理解しやすいかもしれない．&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;h4 id="より詳細な理解">より詳細な理解&lt;/h4>
&lt;p>simple_control2.pyについてより詳細に解説します．&lt;/p>
&lt;details class="spoiler " id="spoiler-16">
&lt;summary>コンストラクタ&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-python"> def __init__(self):
rospy.init_node('simple_controller', anonymous=True)
# Publisher
self.cmd_vel_pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)
# Subscriber
odom_sub = rospy.Subscriber('/odom', Odometry, self.callback_odom)
self.x = None
self.y = None
self.yaw = None
while self.x is None:
rospy.sleep(0.1)
&lt;/code>&lt;/pre>
&lt;p>上にも述べた通り，&lt;code>__init__&lt;/code>はコンストラクタと呼ばれ，オブジェクト生成時に自動で呼び出される関数です．
各行について順番に見ていきます．&lt;/p>
&lt;pre>&lt;code class="language-python"> rospy.init_node('simple_controller', anonymous=True)
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>simple_controller&lt;/code>という名前のノードを作成しています．&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-python"> self.cmd_vel_pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>rospy.Publisher()&lt;/code>によって，上で作成したノードがpublisherとして機能することを宣言しています．&lt;/li>
&lt;li>このノードは，&lt;code>/cmd_vel&lt;/code>というトピックに対して，&lt;code>Twist&lt;/code>というデータ型のメッセージを送信しています．
&lt;ul>
&lt;li>&lt;code>Twist&lt;/code>の情報は，&lt;a href="http://wiki.ros.org/geometry_msgs">geometry_msgsのドキュメント&lt;/a>より確認できます．&lt;/li>
&lt;li>&lt;code>Twist&lt;/code>は速度３成分と角速度３成分を格納するデータ型です．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>第２引数のqueue_sizeは，メッセージを送信する命令が，許容できる周期より短い場合に，メッセージをキューにためておく数を指定します．
&lt;ul>
&lt;li>ここでは，10個までキューにためておくことを指定しています．&lt;/li>
&lt;li>たまった数が10個より少ない場合には，古い順にメッセージをパブリッシュしていきます．&lt;/li>
&lt;li>たまった数が10個に達した場合には，最も古いメッセージを破棄します．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-python"> odom_sub = rospy.Subscriber('/odom', Odometry, self.callback_odom)
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>rospy.Subscriber()&lt;/code>によって，作成したノードがsubscriberとして機能することを宣言しています．&lt;/li>
&lt;li>このノードは，&lt;code>/odom&lt;/code>というトピックから，&lt;code>Odometry&lt;/code>というデータ型のメッセージを受信しています．
&lt;ul>
&lt;li>&lt;code>Odometry&lt;/code>の情報は，&lt;a href="http://wiki.ros.org/nav_msgs">nav_msgsのドキュメント&lt;/a>より確認できます．&lt;/li>
&lt;li>&lt;code>Odometry&lt;/code>は，位置と姿勢，及び速度と角速度を格納するデータ型です．&lt;/li>
&lt;li>ここでは，&lt;code>Odometry&lt;/code>には，ルンバの現在の位置や運動の様子が格納されており，それを受信しています．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>rospy.Subscriber()の第三引数として，&lt;code>self.callback_odom&lt;/code>というコールバック関数を指定しています．
&lt;ul>
&lt;li>subscriberにはコールバック関数を指定する必要があります．&lt;/li>
&lt;li>コールバック関数とは，subscriberがメッセージを受信したときに実行される関数のことです．
&lt;ul>
&lt;li>コールバック関数は，メッセージを引数として実行します．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>コールバック関数の中身は，後述します．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-python"> self.x = None
self.y = None
self.yaw = None
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>アトリビュートを定義しています．&lt;/li>
&lt;li>クラスの定義の中で&lt;code>self.&amp;lt;name&amp;gt;&lt;/code>の形式で表される変数は，そのクラスのオブジェクトが持つ&amp;quot;attribute(アトリビュート)&amp;ldquo;と呼ばれます．
&lt;ul>
&lt;li>アトリビュートには，そのclassの定義の中であればどこからでもアクセスできます．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>ここでは，&lt;code>self.x&lt;/code>, &lt;code>self.y&lt;/code>, &lt;code>self.yaw&lt;/code>というアトリビュートを定義しています．
&lt;ul>
&lt;li>これらのアトリビュートは，後述するコールバック関数の中で値が更新されます．&lt;/li>
&lt;li>このアトリビュートには，ロボットの現在の位置や姿勢が格納されます．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-python"> while self.x is None:
rospy.sleep(0.1)
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>self.x&lt;/code>がNoneである間，0.1秒間隔で待機し続けます．&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-17">
&lt;summary>コールバック関数&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-python"> def callback_odom(self, data):
self.x = data.pose.pose.position.x
self.y = data.pose.pose.position.y
self.yaw = self.get_yaw_from_quaternion(data.pose.pose.orientation)
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>コンストラクタの項目で説明した通り，subscriberを定義する際にはコールバック関数を指定する必要があります．&lt;/li>
&lt;li>コールバック関数はsubscriberがメッセージを受信した際，そのメッセージを引数として実行する関数でした．&lt;/li>
&lt;li>上のコールバック関数では，引数&lt;code>data&lt;/code>には，&lt;code>Odometry&lt;/code>型のメッセージが格納されます．
&lt;ul>
&lt;li>&lt;code>data.pose.pose.position&lt;/code>という書き方によって，Odometry型の中の，位置を表すpositionという要素にアクセスしています．&lt;/li>
&lt;li>同様に，&lt;code>data.pose.pose.orientation&lt;/code>という書き方によって，Odometry型の中の，姿勢を表すorientationという要素にアクセスしています．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>コンストラクタで定義していたアトリビュート&lt;code>self.x&lt;/code>, &lt;code>self.y&lt;/code>, &lt;code>self.yaw&lt;/code>に，メッセージから得られた位置と姿勢を格納しています．
&lt;ul>
&lt;li>&lt;code>self.yaw&lt;/code>に値を格納する時に使用している関数&lt;code>get_yaw_from_quaternion()&lt;/code>については，後述します．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>このコールバック関数が一度でも呼ばれると，&lt;code>self.x&lt;/code>に入っているNoneの値が上書きされ，コンストラクタの中のwhile文が終了します．&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-18">
&lt;summary>get_yaw_from_quaternion関数&lt;/summary>
&lt;p>&lt;p>go_straight関数やturn_right関数とは順番が前後しますが，先にget_yaw_from_quaternion関数について説明します．&lt;/p>
&lt;pre>&lt;code class="language-python"> def get_yaw_from_quaternion(self, quaternion):
e = tf.transformations.euler_from_quaternion(
(quaternion.x, quaternion.y, quaternion.z, quaternion.w))
return e[2]
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>tfモジュールのeuler_from_quaternion関数を利用しています．
&lt;ul>
&lt;li>euler_from_quaternion()は，クォータニオン(4要素)を引数として，オイラー角(3要素)を返す関数です．&lt;/li>
&lt;li>クォータニオンについてはLearn/オドメトリのセンサ情報を用いた制御/クォータニオンの項目で説明しました．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>Odometry&lt;/code>型のメッセージのうち，姿勢を表すorientationという要素は，クォータニオンで表されているため，オイラー角で制御したい場合には，この関数を用いてオイラー角に変換する必要があります．&lt;/li>
&lt;li>ルンバはxy平面上を動くため，z軸周りのオイラー角さえわかれば十分です．そのため，このget_yaw_from_quaternion関数ではオイラー角のz軸成分(第2成分)のみを返しています．&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-19">
&lt;summary>go_straight関数&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-python"> def go_straight(self, dis, velocity=0.3):
vel = Twist()
x0 = self.x
y0 = self.y
while(np.sqrt((self.x-x0)**2+(self.y-y0)**2)&amp;lt;dis):
vel.linear.x = velocity
vel.angular.z = 0.0
self.cmd_vel_pub.publish(vel)
rospy.sleep(0.1)
self.stop()
&lt;/code>&lt;/pre>
&lt;p>ロボットを直進させる関数です．順に説明します&lt;/p>
&lt;pre>&lt;code> vel = Twist()
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>Twist&lt;/code>型のオブジェクトを生成しています．&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-python"> x0 = self.x
y0 = self.y
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>self.x, self.yには，コールバック関数で更新された(直前の)ルンバの位置が格納されています．それをx0, y0に代入しています．&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-python"> while(np.sqrt((self.x-x0)**2+(self.y-y0)**2)&amp;lt;dis):
vel.linear.x = velocity
vel.angular.z = 0.0
self.cmd_vel_pub.publish(vel)
rospy.sleep(0.1)
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>点(self.x, self.y)と点(x0, y0)の距離が指定したdisより小さい間，while以下の処理を繰り返します．
&lt;ul>
&lt;li>velの並進成分のx成分に，引数で指定したvelocityの値を格納します．&lt;/li>
&lt;li>velの回転成分のz成分(z軸周りの角速度)に，0を格納します．&lt;/li>
&lt;li>コンストラクタの中で定義したpublisherである&lt;code>self.cmd_vel_pub&lt;/code>の.publish()関数を用いて，publishを行います．
&lt;ul>
&lt;li>引数にvelを指定しているので，確かにTwist型のメッセージをパブリッシュしています．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>rospy.sleep(0.1)&lt;/code>で0.1秒待ち，次のループに入ります．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-python"> self.stop()
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>while文が終了したら，ロボットを停止させます．
&lt;ul>
&lt;li>stop関数については，説明を省略します．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>turn_right, turn_left関数についても，go_straight関数の説明と同様なので省略します．&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;p>単純に &amp;ldquo;(角)速度 * 時間&amp;rdquo; によって移動の姿勢を指定しているのではなく，オドメトリのセンサ情報を使いながら，
目標の姿勢に到達するように制御していることを再度強調しておきます．&lt;/p>
&lt;p>pythonのコードの読み方についての基本的な説明は上の説明で尽きているので，
余力があれば（なくても）各自&lt;a href="https://github.com/matsuolab/roomba_hack" target="_blank" rel="noopener">roomba_hackリポジトリ&lt;/a>
上の気になったコードを読んでみましょう．&lt;/p>
&lt;h2 id="演習">演習&lt;/h2>
&lt;details class="spoiler " id="spoiler-20">
&lt;summary>【jetson・開発マシン】それぞれdockerコンテナを起動&lt;/summary>
&lt;p>&lt;p>．
jetsonでdockerコンテナを起動&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC):~$ ssh roomba_dev1
(jetson):~$ cd ~/group_a/roomba_hack
(jetson):~/group_a/roomba_hack ./RUN-DOCKER-CONTAINER.sh
(jetson)(docker):~/roomba_hack#
&lt;/code>&lt;/pre>
&lt;p>開発PCでdockerコンテナを起動&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC):~$ cd ~/group_a/roomba_hack
(開発PC):~/group_a/roomba_hack ./RUN-DOCKER-CONTAINER.sh 192.168.10.7x
(開発PC)(docker):~/roomba_hack#
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-21">
&lt;summary>【jetson】ROSマスタ，各種ノードを起動&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-shell">(jetson)(docker):~/roomba_hack# roslaunch roomba_bringup bringup.launch
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;h3 id="rosメッセージの可視化">ROSメッセージの可視化&lt;/h3>
&lt;details class="spoiler " id="spoiler-22">
&lt;summary>【開発PC】topicの確認&lt;/summary>
&lt;p>&lt;p>&lt;code>/odom&lt;/code>の型を確認&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker):~/roomba_hack# rostopic type /odom
&lt;/code>&lt;/pre>
&lt;p>&lt;code>/odom&lt;/code>の中身を確認&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker):~/roomba_hack# rostopic echo /odom
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-23">
&lt;summary>オドメトリを使ったフィードバック制御&lt;/summary>
&lt;p>&lt;p>&lt;code>simple_control2.py&lt;/code>を実行してみよう．&lt;/p>
&lt;p>開発PCでteleopのコードを実行しましょう&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker):~/roomba_hack# roslaunch roomba_teleop teleop.launch
&lt;/code>&lt;/pre>
&lt;p>このプログラムを動かすときには，コントローラの&lt;code>Y&lt;/code>ボタンを押してから&lt;code>B&lt;/code>ボタンを押して&lt;code>auto&lt;/code>モードにしておきましょう．&lt;/p>
&lt;p>1メートルほど前に進んだあと，左に90度程度旋回し，右に90度程度旋回したら成功です．&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker):~/roomba_hack# rosrun navigation_tutorial simple_control2.py
&lt;/code>&lt;/pre>
&lt;p>try it! &lt;code>simple_control2.py&lt;/code>の中身を読んでコードを変更してみよう&lt;/p>
&lt;/p>
&lt;/details></description></item><item><title>最終プロジェクト</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap8/final_project/</link><pubDate>Thu, 22 Jun 2023 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap8/final_project/</guid><description>&lt;h2 id="最終課題について">最終課題について&lt;/h2>
&lt;p>最終課題発表会の日程は&lt;mark>未定&lt;/mark>です(2023-06-22現在)。&lt;/p>
&lt;p>それまでに各チームで以下のタスクを行うコードを準備してください。
また、チームでGitHubにリポジトリを作成し、準備したコードをアップロードしてください。&lt;/p>
&lt;p>すべてのタスクを完璧に実装しようとすると少し大変なので、まずは、ヒントを参考に「はじめの一歩」を実装するのを目指しましょう。&lt;/p>
&lt;p>ルールの質問、実装のやり方などわからないことは #q-roomba で質問お願いします！
また、角川でも質問対応デーを設ける予定です。&lt;/p>
&lt;h3 id="ルール">ルール&lt;/h3>
&lt;p>1チームずつTask1とTask2の2つのタスクを行い、その合計点を競います。&lt;/p>
&lt;p>それぞれのタスクは図の環境で行われます。(角川にある環境です。)&lt;/p>
&lt;figure id="figure-タスクがおこなわれるフィールド図">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../field.png" alt="タスクがおこなわれるフィールド図" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
タスクがおこなわれるフィールド図
&lt;/figcaption>&lt;/figure>
&lt;p>それぞれのTaskのStaring Pointではルンバの自己位置を合わせることはできますが、一度ルンバが動き始めたら人が介入することができないことに注意してください。(リスタートを除く)&lt;/p>
&lt;h4 id="task1">Task1&lt;/h4>
&lt;details class="spoiler " id="spoiler-2">
&lt;summary>ルール&lt;/summary>
&lt;p>&lt;p>Task1では、3分の制限時間の間で、Room1のStarting Pointからルンバを自律移動させ、Area1内に落ちている5つの物体を避けながらRoom2へと移動することが目標になります。&lt;/p>
&lt;p>途中でロボットが停止した場合などは再びStarting Pointからリスタートすることができます。&lt;/p>
&lt;p>また、Area1内に落ちている5つの物体を検出し、正しく分類することで追加ポイントを獲得することができます。&lt;/p>
&lt;p>タスク終了時にArea1内で出てきた物体の名前をターミナルに表示してください。&lt;/p>
&lt;p>また、5つの物体は以下の8個の物体からランダムに選択されます。&lt;/p>
&lt;figure id="figure-task1で出現する物体">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../objects.jpeg" alt="Task1で出現する物体" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Task1で出現する物体
&lt;/figcaption>&lt;/figure>
&lt;p>物体の名前は左から順に&lt;/p>
&lt;ul>
&lt;li>chips can&lt;/li>
&lt;li>mini soccor ball&lt;/li>
&lt;li>rubic cube&lt;/li>
&lt;li>banana&lt;/li>
&lt;li>apple&lt;/li>
&lt;li>strawberry&lt;/li>
&lt;li>toy plane&lt;/li>
&lt;li>wood block
です。&lt;/li>
&lt;/ul>
&lt;p>実際に使用する物体は角川に置いてあります。&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-3">
&lt;summary>採点基準&lt;/summary>
&lt;p>&lt;p>ゴール得点と物体検出得点それぞれ100点満点です。また、ゴール得点と物体検出得点それぞれの得点が負になることはありません。&lt;/p>
&lt;p>ゴール得点内訳(100点満点)&lt;/p>
&lt;p>制限時間以内にゴール(Room2)に辿り着けたら100点、物体に衝突するたびに物体ごとに-20点、加えて、ロボットをStarting Pointからリスタートする度に-10点&lt;/p>
&lt;p>物体検出得点内訳(100点満点)&lt;/p>
&lt;p>検出結果の分類結果が正しければ物体ごとに+20点、間違っていたら-20点&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-4">
&lt;summary>ヒント&lt;/summary>
&lt;p>&lt;p>はじめの一歩&lt;/p>
&lt;ul>
&lt;li>Task1はまず、ゴールへ移動するコードを作成することを目標にしましょう (スクリプトでナビゲーションを行うためのヒント参照)&lt;/li>
&lt;li>余裕があれば、他のヒントを参照して高得点を目指していきましょう&lt;/li>
&lt;/ul>
&lt;p>スクリプトでナビゲーションを行うためのヒント&lt;/p>
&lt;ul>
&lt;li>スクリプトでナビゲーションを行うコード(&lt;a href="https://matsuolab.github.io/roomba_hack_course/course/chap6/service-actionlib/">https://matsuolab.github.io/roomba_hack_course/course/chap6/service-actionlib/&lt;/a> の演習)を参考に、指定した位置へ移動するコードを書いてみましょう&lt;/li>
&lt;/ul>
&lt;p>障害物を避けながらnavigationするためのヒント&lt;/p>
&lt;ul>
&lt;li>物体検出器を改善するためのヒントおよび &lt;a href="https://matsuolab.github.io/roomba_hack_course/course/chap6/service-actionlib/">https://matsuolab.github.io/roomba_hack_course/course/chap6/service-actionlib/&lt;/a> の総合課題を参照し、課題物体を検出し、それをコストマップに追加することで障害物を避けるコードを書いてみましょう&lt;/li>
&lt;/ul>
&lt;p>より正確な自己位置推定を行うためのヒント&lt;/p>
&lt;ul>
&lt;li>amclのパラメータ調整 (参考: &lt;a href="https://matsuolab.github.io/roomba_hack_course/course/chap4/localization/">https://matsuolab.github.io/roomba_hack_course/course/chap4/localization/&lt;/a> の演習)をしてみましょう&lt;/li>
&lt;li>gmappingを用いてより正確な地図を作成 (参考: &lt;a href="https://matsuolab.github.io/roomba_hack_course/course/chap4/localization/">https://matsuolab.github.io/roomba_hack_course/course/chap4/localization/&lt;/a> の演習)してみましょう&lt;/li>
&lt;li>emcl(&lt;a href="https://github.com/ryuichiueda/emcl">https://github.com/ryuichiueda/emcl&lt;/a>)等の異なる自己位置推定アルゴリズムを使ってみましょう&lt;/li>
&lt;li>Lidarの位置を合わせをより正確に(&lt;a href="https://github.com/matsuolab/roomba_hack/blob/master/catkin_ws/src/roomba/roomba_description/urdf/roomba.urdf.xacro">https://github.com/matsuolab/roomba_hack/blob/master/catkin_ws/src/roomba/roomba_description/urdf/roomba.urdf.xacro&lt;/a> を編集)合わせてみましょう&lt;/li>
&lt;/ul>
&lt;p>物体検出器を改善するためのヒント&lt;/p>
&lt;ul>
&lt;li>自作データを用いて既存モデルの学習 (参考: &lt;a href="https://eng-memo.info/blog/yolo-original-dataset/">https://eng-memo.info/blog/yolo-original-dataset/&lt;/a>) を行ってみましょう&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;h4 id="task2">Task2&lt;/h4>
&lt;details class="spoiler " id="spoiler-5">
&lt;summary>ルール&lt;/summary>
&lt;p>&lt;p>Task2では、3分の制限時間の間で、Room2のStarting Pointからルンバを自律移動させ、Area2にいる2人の人のうち、手を振っている人の前で停止することが目標になります。&lt;/p>
&lt;p>また、2人の人がArea2にある2つの椅子に座っており、そのうち一方のみが手を振っていることが保証されています。&lt;/p>
&lt;p>途中でロボットが停止した場合などは再びStarting Pointからリスタートすることができます。&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-6">
&lt;summary>採点基準&lt;/summary>
&lt;p>&lt;p>Task2全体で150点満点です、また、Task2の得点が負になることはありません。&lt;/p>
&lt;p>時間以内にいずれかの人の前に移動が成功し、その場で停止する(人の50cm以内に到達する)+70点&lt;/p>
&lt;p>上に加え、正しい人(手を振っている人)の前に移動が成功する+80点&lt;/p>
&lt;p>加えて、ロボットをStarting Pointからリスタートする度に-10点&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-7">
&lt;summary>ヒント&lt;/summary>
&lt;p>&lt;p>はじめの一歩&lt;/p>
&lt;ul>
&lt;li>Task2はまず、人を検出して移動するコードを作成することを目標にしましょう (人を検出して移動するためのヒント参照)&lt;/li>
&lt;li>余裕があれば手を振っている人の検出にチャレンジしてみましょう&lt;/li>
&lt;/ul>
&lt;p>人を検出して移動するためのヒント&lt;/p>
&lt;ul>
&lt;li>人を検出する部分については三次元画像処理で扱ったYOLOv3で検出することができます&lt;/li>
&lt;li>検出した結果に対応する深度画像から距離を取得することで、人の近くへ移動するコードを書くことができます&lt;/li>
&lt;li>(参考: &lt;a href="https://matsuolab.github.io/roomba_hack_course/course/chap5/three-dimensions/">https://matsuolab.github.io/roomba_hack_course/course/chap5/three-dimensions/&lt;/a> のdetection_distance.py)&lt;/li>
&lt;li>さらに余裕があれば、深度画像を点群等に変換するとより正確な移動が可能になります&lt;/li>
&lt;/ul>
&lt;p>手を振っている人の検出&lt;/p>
&lt;ul>
&lt;li>学習済みのKeypoint R-CNNを用いることで人間の手や腕の位置などのキーポイントを推定することができます。&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details></description></item><item><title>開発環境</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap1/%E9%96%8B%E7%99%BA%E7%92%B0%E5%A2%83/</link><pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap1/%E9%96%8B%E7%99%BA%E7%92%B0%E5%A2%83/</guid><description>&lt;p>ロボットシステムの開発環境に使われている要素の概要を理解する&lt;/p>
&lt;!--
## スライド
https://docs.google.com/presentation/d/1-q6zq3vV91GTj7mw9uqwT4B8LyHDpFHBNVi4lEyCa5A/edit?usp=sharing
-->
&lt;h2 id="learn">Learn&lt;/h2>
&lt;h3 id="linuxコマンド">Linuxコマンド&lt;/h3>
&lt;p>コンピュータやロボットの研究・開発では、LinuxというOS(Operating System)がよく使用されます。&lt;br>
ROSはLinux(とくにUbuntuというディストリビューション)で動かすことを想定されているので、ROSを使うにはある程度Linuxの知識が必要になります。
Linuxについてあまり知らないという方は、以下のページに目を通しておくと良いと思います。&lt;br>
&lt;a href="https://kitsune.blog/engineer/linux" target="_blank" rel="noopener">Linuxについてまとまっているページ&lt;/a>&lt;br>
特に、&lt;a href="https://kitsune.blog/linux-command-summary" target="_blank" rel="noopener">Linuxコマンドについて&lt;/a>軽く知っておくと講義が理解しやすくなると思います。&lt;/p>
&lt;pre>&lt;code>&amp;quot;&amp;quot;&amp;quot;
ここではLinuxのコマンドを十分に説明できないので、コマンドの例を挙げることに留めます。
詳しいサイトに沿って自分で使いながら覚えていくことをお勧めします。
&amp;quot;&amp;quot;&amp;quot;
# カレントディレクトリ(自分が今いるディレクトリ)を確認
pwd
# ディレクトリ内のファイル・ディレクトリの表示
ls
# カレントディレクトリを変更
cd &amp;lt;DirectoryName&amp;gt;
# ディレクトリ作成
mkdir &amp;lt;NewDirectoryName&amp;gt;
# ディレクトリ削除
rmdir &amp;lt;DirectoryName&amp;gt;
# ファイル作成
touch &amp;lt;NewFileName&amp;gt;
# ファイル消去
rm &amp;lt;FileName&amp;gt;
# ファイルの内容を表示
cat &amp;lt;FileName&amp;gt;
&lt;/code>&lt;/pre>
&lt;h3 id="エディタ">エディタ&lt;/h3>
&lt;p>プログラミング言語でコードを書くときに使用するツールをEditor（エディタ）と呼びます。&lt;br>
テキストファイルを編集するツールなのでメモ帳でも同じ事ができるのですが、コード編集用のエディタは便利な機能が多く、効率よく書けるようになります。&lt;br>
研究室のPCでは以下の二つが使えます。&lt;/p>
&lt;ul>
&lt;li>vim
&lt;ul>
&lt;li>シンプルで使いやすいエディタ。&lt;/li>
&lt;li>macだと標準で使える。
&lt;ul>
&lt;li>ターミナルで&lt;code>vimtutor&lt;/code>を実行するとチュートリアルが受けられる.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Windowsだとインストールする必要がある。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>vscode
&lt;ul>
&lt;li>visual studio code&lt;/li>
&lt;li>ダウンロードする必要がある&lt;/li>
&lt;li>さまざまな機能を追加でき、とても便利&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=csOaPNMDEwg&amp;amp;ab_channel=%E3%81%97%E3%81%BE%E3%81%B6%E3%83%BC%E3%81%AEIT%E5%A4%A7%E5%AD%A6" target="_blank" rel="noopener">詳しい動画&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="gitgithub">Git/GitHub&lt;/h3>
&lt;ul>
&lt;li>Gitとは
&lt;ul>
&lt;li>
&lt;p>ファイルのバージョン管理が簡単にできるツール。&lt;/p>
&lt;p>使い方を知っておくと開発が快適になります。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://qiita.com/noshishi/items/2821c01d590bf9c96038" target="_blank" rel="noopener">詳しい記事(コマンドなし)&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://qiita.com/satona-oinuma/items/97205ca0ce04dcae2adb" target="_blank" rel="noopener">詳しい記事(コマンドあり)&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>GitHubとは
&lt;ul>
&lt;li>
&lt;p>gitで管理しているファイルを他の人と共有できるようにするサービス。&lt;/p>
&lt;p>チーム開発で大変重宝します。&lt;br>
自分が書いたコードを公開して世界中の人に使ってもらったり、他の人が公開しているコードを使わせてもらうこともできます。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.co.jp/">https://github.co.jp/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://qiita.com/b150005/items/508009234bf9813b230f" target="_blank" rel="noopener">詳しい記事&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://learn.utcode.net/docs/team-development/git-workflow/" target="_blank" rel="noopener">GitとGitHubを用いたワークフロー&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>このサイトもGitHubを使って開発しています。&lt;a href="https://github.com/matsuolab/roomba_hack_course" target="_blank" rel="noopener">このサイトのリポジトリ&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>公開されているリポジトリの例&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/gundam-global-challenge/gundam_robot">https://github.com/gundam-global-challenge/gundam_robot&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="docker">Docker&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Dockerとは&lt;/p>
&lt;p>「データやプログラムを隔離できる」仕組み。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>例えば、コンピュータの中でシステムAとシステムBを動かしたいとします。そして、これらは他のシステムCに依存しているものとします。&lt;br>
もし、AがCのver.2にのみ対応していて、BはCのver.3にのみ対応していた場合、Bを実行できるようにCをver.3にしてしまうと、Aが実行できなくなってしまいます。&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../docker_1.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>このような場合、dockerコンテナを複数作成し（コンテナI、コンテナIIとします）、&lt;/p>
&lt;ul>
&lt;li>コンテナIの中にはプログラムAとCのバージョン2をインストールして使い、&lt;/li>
&lt;li>コンテナIIの中にはプログラムBとCのバージョン3をインストールして使用する&lt;/li>
&lt;/ul>
&lt;p>のようなことことができます。&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../docker_2.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>コンテナの中の環境はPC本体の環境からは隔離されるため、安全に開発をすることができます(他の人が書いたプログラムが動かなくなるということも防げる)。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://kitsune.blog/docker-summary" target="_blank" rel="noopener">詳しい記事&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;!-- - DockerFileのビルド
```
docker build -t &lt;image_name>:&lt;tag_name> -f &lt;Dockerfile> &lt;relative_dir>
```
- Docker Image
```
# Docker image一覧
docker images
# Docker Imageのダウンロード
docker pull &lt;image_name>:&lt;tag_name>
# 削除
docker rmi &lt;image_id>
# 不要なDocker imageを消す
docker image prune
```
- Docker Container
```
# Docker containerの起動
docker run &lt;image_name> &lt;command>
# Docker container一覧
docker ps -a
# Docker containerに接続
docker exec -it &lt;container_name> bash
```
-->
&lt;!-- ※`docker run`でよく使うオプション
- `-it`
- 標準入出力有効になる
- `--name &lt;container_name>`
- コンテナの名前の指定
- `--rm`
- コンテナを抜けた際に自動的にコンテナを削除する
- `--gpus all`
- コンテナに全gpuを渡す
- gpuの個数を指定する場合は all の代わりに数字(0, 1,...)
- gpuを指定する場合は `--gpus '"device=0,1"'`
- `-v &lt;host/path/to/dir:container/path/to/dir>`
- コンテナ内にホストのディレクトリをマウントする
- `-p &lt;host_port>:&lt;container_port>`
- ホストのポートをコンテナのポートにマップする
- コンテナ内でwebサーバを動かす場合などに使う
- `--net=host`
- コンテナとホストでネットワークを共有する(IPアドレスなどが同じになる)
- ROSノードをコンテナ内で動かす場合などはこれを使うと楽
- `--privileged`
- コンテナからのデバイスへのアクセスを許可
- コンテナからWEBカメラにアクセスしたいときなど
-->
&lt;h3 id="ssh">ssh&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://e-words.jp/w/SSH.html" target="_blank" rel="noopener">sshとは&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>sshを使用することで、開発PCからルンバに載っているjetsonというコンピュータを遠隔で操作することや、各自のPCから開発PCを遠隔で操作することができる。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;!--
コマンドだけあってもわからないと思うので
```
ssh &lt;username>@&lt;hostname> -p &lt;port> -i &lt;identity_file>
```
-->
&lt;h2 id="演習">演習&lt;/h2>
&lt;p>演習には個人PC, 開発PC, ルンバに搭載されているjetsonの3種類のコンピュータを用います。&lt;/p>
&lt;p>開発PC : robot_dev系, hsr_dev系&lt;/p>
&lt;p>jetson : roomba_dev系&lt;/p>
&lt;!--
&lt;details class="spoiler " id="spoiler-2">
&lt;summary>【ssh】開発用PCにsshする&lt;/summary>
&lt;p>&lt;p>個人PCから開発PCにsshする&lt;/p>
&lt;pre>&lt;code class="language-shell">(個人PC):~$ vim ~/.ssh/config
(個人PC):~$ ssh robot_dev2
&lt;/code>&lt;/pre>
&lt;p>sshに成功すると&lt;/p>
&lt;pre>&lt;code>robot_dev2@robot-dev2:~$
&lt;/code>&lt;/pre>
&lt;p>などと表記が変わり、開発PCに接続できたことが確認できます。&lt;/p>
&lt;/p>
&lt;/details>
-->
&lt;details class="spoiler " id="spoiler-3">
&lt;summary>【Linuxコマンド】グループのディレクトリを作成し移動する&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-sh">(開発PC):~$ mkdir 23_group_x
(開発PC):~$ cd 23_group_x
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-4">
&lt;summary>【git】roomba_hackリポジトリをcloneし移動する&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-sh">(開発PC):~/23_group_x$ git clone https://github.com/matsuolab/roomba_hack.git
(開発PC):~/23_group_x$ ls
# 23_group_xディレクトリの中に新しいディレクトリができていることを確認
(開発PC):~/23_group_x$ cd roomba_hack
(開発PC):~/23_group_x/roomba_hack$ ls
&lt;/code>&lt;/pre>
&lt;p>&lt;a href="https://github.com/matsuolab/roomba_hack">https://github.com/matsuolab/roomba_hack&lt;/a> をそのままダウンロードできたことが確認できると思います。&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-5">
&lt;summary>【git】ブランチを確認する&lt;/summary>
&lt;p>&lt;p>git branchコマンドを使ってみましょう。&lt;/p>
&lt;pre>&lt;code class="language-sh"># ローカルブランチの一覧を表示
(開発PC):~/23_group_x/roomba_hack$ git branch
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-6">
&lt;summary>【docker】roomba_hackの開発環境のdockerイメージをビルドする&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-sh"># shellファイルの中身をcatコマンドで確認してみます。
(開発PC):~/23_group_x/roomba_hack$ cat BUILD-DOCKER-IMAGE.sh
# ファイルの中身が表示される
# ファイルの最後の
# docker build . -f docker/${DOCKERFILE_NAME} -t ${IMAGE_NAME}:${TAG_NAME} --build-arg BASE_IMAGE=${BASE_IMAGE}
# の部分でDockerイメージのビルドを実行するようです。
# shellファイルを実行してdockerイメージのビルドを行います。
(開発PC):~/23_group_x/roomba_hack$ ./BUILD-DOCKER-IMAGE.sh
&lt;/code>&lt;/pre>
&lt;p>「イメージ」とは、dockerコンテナを作成するための素となるもので、コンテナの設計図のようなものです。上のコマンドを実行することで、roomba_hackの開発環境のdockerイメージが作成されます（まだコンテナ自体は作っていません）。&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-7">
&lt;summary>【ssh】jetsonにsshする&lt;/summary>
&lt;p>&lt;p>開発用PCからルンバに載っているjetson nanoへsshします。&lt;/p>
&lt;pre>&lt;code class="language-sh">(開発PC):~/23_group_x/roomba_hack$ ssh roomba_dev2
roomba_dev2@roomba-dev-jetson2:~$
&lt;/code>&lt;/pre>
&lt;p>先頭の表記が&lt;code>roomba_dev2@roomba-dev-jetson2&lt;/code>と変わり、jetsonへ接続されたことがわかります。&lt;/p>
&lt;p>jetsonでも同様にグループのディレクトリを作成し、移動し、roomba_hackリポジトリをcloneしてみましょう。&lt;/p>
&lt;/p>
&lt;/details>
&lt;!--
&lt;details class="spoiler " id="spoiler-8">
&lt;summary>【ssh】VNCを使う&lt;/summary>
&lt;p>&lt;p>個人PCから開発PCにsshで接続&lt;/p>
&lt;pre>&lt;code class="language-shell">(個人PC):~$ ssh robot_dev2 -L 5900:localhost:5900
&lt;/code>&lt;/pre>
&lt;p>手元のVNC viewerでlocalhost:5900を開く&lt;/p>
&lt;/p>
&lt;/details>
-->
&lt;!--
TODO:
- RUN-DOCKER-CONTAINER.shの中身を説明する
- BUILD-DOCKER-IMAGE.shの中身を説明する
- sshに必要な設定を説明する
- VNCに必要な設定を説明する
- VNC viewerの使い方を説明する
--></description></item><item><title>serviceとactionlib</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap6/service-actionlib/</link><pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap6/service-actionlib/</guid><description>&lt;h2 id="learn">Learn&lt;/h2>
&lt;p>ここまでトピックを使った通信を使ってロボットシステムを構築してきました．
トピック通信は，メッセージを出版(publish，配信とも訳される)・購読（subscribe）することで通信する，相手を仮定しない非同期な通信方法でした．&lt;/p>
&lt;p>しかし，もっと複雑なシステムを組む場合には，「相手の処理の結果を呼び出し側で受け取って知りたい」など様々な場合が考えられます．&lt;/p>
&lt;p>このようなより複雑な通信を実現するための通信方式として，ROSにはサービス（service）とアクション（actionlib）が用意されています．&lt;/p>
&lt;h3 id="service">service&lt;/h3>
&lt;p>これまで利用してきたトピック通信は，通信の相手を仮定しない（相手がいようといまいと関係ない）ため，ロボットシステムに特有な非同期通信・処理を実現するために簡単な方法でした．&lt;/p>
&lt;p>一方で，他のノードに対して「特定の処理の依頼をして，その結果を待ちたい」場合など，同期的・双方向な通信が必要になることがあります．
例えば，あるノードの設定を変更をして，それが成功したかどうかを知りたい場合などに使えます．
サービスを使った通信は，「クライアント・サーバ」型の通信（クライアントサーバモデル, client-server model）となり，クライアントがサーバにリクエストを送ると，サーバがレスポンスを返すような仕組みになっています．&lt;/p>
&lt;p>pythonでは&lt;code>rospy.service&lt;/code>を使ってサーバを，&lt;code>rospy.service_proxy&lt;/code>を使ってクライアントを簡単に実装できます（&lt;a href="http://wiki.ros.org/ja/ROS/Tutorials/WritingServiceClient%28python%29" target="_blank" rel="noopener">参考URL&lt;/a>）．&lt;/p>
&lt;p>また，コマンドラインからは&lt;/p>
&lt;pre>&lt;code class="language-bash">rosservice call [service] [args]
&lt;/code>&lt;/pre>
&lt;p>として，簡単にクライアントを作成できますし，システム上に存在するサービスの一覧は&lt;/p>
&lt;pre>&lt;code class="language-bash">rosservice list
&lt;/code>&lt;/pre>
&lt;p>とすることで表示できます．あるサービスのメッセージがどのように定義されているかは，&lt;/p>
&lt;pre>&lt;code class="language-bash">rosservice type [service]
&lt;/code>&lt;/pre>
&lt;p>で調べられます．&lt;/p>
&lt;h3 id="actionlib">actionlib&lt;/h3>
&lt;p>ここまで，トピック通信を使うことで相手を仮定しない非同期通信を，サービスを使った通信を行うことで相手のレスポンスを待つ同期的な通信を実現できることを見てきました．&lt;/p>
&lt;p>サービスによる通信では，クライアントはサーバからのレスポンスを待つため，サーバで長い時間がかかるような処理を行う（計算量が大きい，または，移動に時間がかかるなど）場合には，クライアントの処理が長い間停止してしまうという問題があります．&lt;/p>
&lt;p>そのため，処理の呼び出し側のプログラムをブロックせずに，かつ，処理の結果（や途中経過）を知れるような非同期通信が欲しくなります．
この要求を満たすのが，ROSのアクション(actionlib)です．&lt;/p>
&lt;p>actionlibは，実はトピック通信の組み合わせとして構成されており，&lt;code>goal&lt;/code>（命令），&lt;code>result&lt;/code>（処理の結果），&lt;code>feedback&lt;/code>（途中経過），&lt;code>status&lt;/code>（サーバの状態），&lt;code>cancel&lt;/code>（命令の取り消し）の5つのトピックからなります．
このあたりの仕様は，&lt;a href="https://qiita.com/srs/items/a39dcd24aaeb03216026#%E6%A6%82%E8%A6%81" target="_blank" rel="noopener">qiitaのROS講座&lt;/a>が詳しいので参照してください．&lt;/p>
&lt;p>pythonでは，actionlibのサーバやクライアントも，&lt;/p>
&lt;pre>&lt;code class="language-python">import actionlib
&lt;/code>&lt;/pre>
&lt;p>したのちに，他の通信方式と同様に&lt;code>actionlib.SimpleActionServer&lt;/code>として，簡単に作成できます（&lt;a href="http://wiki.ros.org/ja/actionlib_tutorials/Tutorials/Writing%20a%20Simple%20Action%20Server%20using%20the%20Execute%20Callback%20%28Python%29" target="_blank" rel="noopener">ドキュメント&lt;/a>）．&lt;/p>
&lt;p>今回の演習では，簡単のためaction serverの作成は行いません．
変わりに，移動のためのactionとして，&lt;code>move_base&lt;/code>パッケージの中で定義されている&lt;code>move_base&lt;/code>というactionを使うことにしましょう．&lt;/p>
&lt;p>実はこのパッケージは&lt;/p>
&lt;pre>&lt;code class="language-bash">roslaunch navigation_tutorial navigation.launch
&lt;/code>&lt;/pre>
&lt;p>して&lt;code>move_base&lt;/code>ノードを起動した際に既に利用されていました（これまでは，そのパッケージの中でサブスクライバとして定義された&lt;code>move_base_simple/goal&lt;/code>というトピックにpublishすることで移動をしていました）．&lt;/p>
&lt;p>&lt;code>move_base&lt;/code>のパッケージの詳細は&lt;a href="http://wiki.ros.org/move_base" target="_blank" rel="noopener">ドキュメント&lt;/a>を見て確認してみてください．&lt;/p>
&lt;p>同様に，action clientも&lt;code>actionlib.SimpleActionClient&lt;/code>を利用することで簡単に作成できます．&lt;/p>
&lt;p>例えば，&lt;code>move_base&lt;/code>のaction clientの実装する際には，&lt;/p>
&lt;pre>&lt;code class="language-python">import actionlib
import tf
from move_base_msgs.msg import MoveBaseAction, MoveBaseGoal
from geometry_msgs.msg import Quaternion
action_client = actionlib.SimpleActionClient('move_base', MoveBaseAction)
action_client.wait_for_server() # action serverの準備ができるまで待つ
goal = MoveBaseGoal() # goalのメッセージの定義
goal.target_pose.header.frame_id = 'map' # マップ座標系でのゴールとして設定
goal.target_pose.header.stamp = rospy.Time.now() # 現在時刻
# ゴールの姿勢を指定
goal.target_pose.pose.position.x = X
goal.target_pose.pose.position.y = Y
q = uaternion_from_euler(0, 0, YAW) # 回転はquartanionで記述するので変換
goal.target_pose.pose.orientation = Quaternion(q[0], q[1], q[2], q[3])
action_client.send_goal(goal) # ゴールを命令
&lt;/code>&lt;/pre>
&lt;p>のようにクライアントの&lt;code>send_goal&lt;/code>メソッドでゴールを指定できます．&lt;/p>
&lt;p>その後，&lt;/p>
&lt;pre>&lt;code class="language-python">action_client.wait_for_result(rospy.Duration(30))
&lt;/code>&lt;/pre>
&lt;p>とすると，結果が返ってくるまで（この場合30秒間），クライアントの処理をブロックできますし，&lt;/p>
&lt;pre>&lt;code class="language-python">result = action_client.wait_for_result(rospy.Duration(30))
&lt;/code>&lt;/pre>
&lt;p>とすることで，&lt;code>result&lt;/code>変数に処理の結果が格納され，確認できます．&lt;/p>
&lt;h2 id="演習">演習&lt;/h2>
&lt;details class="spoiler " id="spoiler-0">
&lt;summary>【jetson・開発マシン】起動準備&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-shell">cd roomba_hack
git fetch
git checkout feature/integrate
(jetson) ./RUN-DOCKER-CONTAINER.sh
(開発マシン) ./RUN-DOCKER-CONTAINER.sh 192.168.10.7x
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-1">
&lt;summary>【開発マシン】scriptベースのnavigationを実行してみる&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-shell">(開発マシン)(docker) roslaunch navigation_tutorial navigation.launch
(開発マシン)(docker) rosrun navigation_tutorial topic_goal.py
(開発マシン)(docker) rosrun navigation_tutorial action_goal.py
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-2">
&lt;summary>【開発マシン】RealSenseで検出した障害物をコストマップに追加してみよう&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-shell">(開発マシン)(docker) roslaunch three-dimensions_tutorial detection_pc.launch
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-3">
&lt;summary>（総合課題）障害物を避けながらnavigationする&lt;/summary>
&lt;p>&lt;p>Lidarに映らない物体も画像ベースで検出しコストマップに追加することでナビゲーション時にぶつからないようにしましょう。&lt;/p>
&lt;p>ヒント&lt;/p>
&lt;ul>
&lt;li>物体検出結果に基づいて物体部分以外をマスクしたデプス画像をpublishする&lt;/li>
&lt;li>depth2pc.launchでそれをsubscribeし、point(cloud)に変換する&lt;/li>
&lt;li>変換されたpointからmap座標系での位置を取得する&lt;/li>
&lt;li>costmapに反映する&lt;/li>
&lt;li>&lt;code>move_base&lt;/code>アクションを使ってナビゲーションを実装しよう．
&lt;ul>
&lt;li>するとactionがタイムアウトした場合や，&lt;code>KeyboardInterrupt&lt;/code>された場合に&lt;code>cancel_goal&lt;/code>メソッドを使うことでactionをキャンセルできるように拡張できるはずです．&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>さらに，PyTorchを使用した自作の分類器やネット上の分類器をシステムに組み込んで（例えばセグメンテーションモデルなど），よりよく動作するように改良してみましょう．&lt;/p>
&lt;/p>
&lt;/details></description></item><item><title>三次元画像処理</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap5/three-dimensions/</link><pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap5/three-dimensions/</guid><description>&lt;h2 id="learn">Learn&lt;/h2>
&lt;p>今回はRealSenseD435というRGBDカメラを用いて三次元画像処理を行っていきましょう。&lt;/p>
&lt;h3 id="rgbdカメラについて">RGBDカメラについて&lt;/h3>
&lt;p>RGBDカメラとは、カラーの他にデプス(深度)を取得できるカメラのことです。
複雑な動作を行うロボットを動かす際には三次元空間の把握が重要となり、RGBDカメラはよく用いられます。
比較的安価でよく利用されるRGBDカメラとして、Intel社製のRealSenseやMicrosoft社製のXtionなどがあります。&lt;/p>
&lt;h3 id="realsense">RealSense&lt;/h3>
&lt;p>今回はRGBDカメラとしてRealSenseD435を使用します。&lt;/p>
&lt;p>ROSで用いる際には標準のラッパー(&lt;a href="https://github.com/IntelRealSense/realsense-ros">https://github.com/IntelRealSense/realsense-ros&lt;/a>)を使用します。&lt;/p>
&lt;p>&lt;code>roslaunch realsense2_camera rs_camera.launch&lt;/code>を行うとデフォルトのトピックとして
RGB画像の&lt;code>/camera/color/image_raw&lt;/code>、
デプス画像の&lt;code>/camera/depth/image_raw&lt;/code>
が利用できます。これらのトピックはいずれも&lt;code>sensor_msgs/Image&lt;/code>型です。&lt;/p>
&lt;p>RealSenseは物理的にRGB画像モジュールとデプス画像モジュールが離れているため、これら2つのトピックはいずれも画像データではあるものの、ピクセルの位置関係が対応しておらずそのままだとうまく画像処理に用いることができませんが、起動時に&lt;code>align:=true&lt;/code>を指定すると、デプス画像をRGB画像のピクセルに対応するように変換された&lt;code>/camera/aligned_depth_to_color/image_raw&lt;/code>トピックを使用できるようになります。&lt;/p>
&lt;h3 id="物体検出">物体検出&lt;/h3>
&lt;p>まずはRGB画像&lt;code>/camera/color/image_raw&lt;/code>のみを用いて三次元ではない画像検出を行っていきましょう。&lt;/p>
&lt;p>以下は&lt;code>/camera/color/image_raw&lt;/code>をSubscribeし、物体検出アルゴリズムであるYOLOv3に入力し、その結果をbounding boxとして描画し、&lt;code>/detection_result&lt;/code>としてPublishするスクリプトです。&lt;/p>
&lt;pre>&lt;code>#!/usr/bin/env python3
import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
from pytorchyolo import detect, models
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import cv2
import copy
class ObjectDetection:
def __init__(self):
rospy.init_node('object_detection', anonymous=True)
# Publisher
self.detection_result_pub = rospy.Publisher('/detection_result', Image, queue_size=10)
# Subscriber
rgb_sub = rospy.Subscriber('/camera/color/image_raw', Image, self.callback_rgb)
self.bridge = CvBridge()
self.rgb_image = None
def callback_rgb(self, data):
cv_array = self.bridge.imgmsg_to_cv2(data, 'bgr8')
cv_array = cv2.cvtColor(cv_array, cv2.COLOR_BGR2RGB)
self.rgb_image = cv_array
def process(self):
path = &amp;quot;/root/roomba_hack/catkin_ws/src/three-dimensions_tutorial/yolov3/&amp;quot;
# load category
with open(path+&amp;quot;data/coco.names&amp;quot;) as f:
category = f.read().splitlines()
# prepare model
model = models.load_model(path+&amp;quot;config/yolov3.cfg&amp;quot;, path+&amp;quot;weights/yolov3.weights&amp;quot;)
while not rospy.is_shutdown():
if self.rgb_image is None:
continue
# inference
tmp_image = copy.copy(self.rgb_image)
boxes = detect.detect_image(model, tmp_image)
# [[x1, y1, x2, y2, confidence, class]]
# plot bouding box
for box in boxes:
x1, y1, x2, y2 = map(int, box[:4])
cls_pred = int(box[5])
tmp_image = cv2.rectangle(tmp_image, (x1, y1), (x2, y2), (0, 255, 0), 3)
tmp_image = cv2.putText(tmp_image, category[cls_pred], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
# publish image
tmp_image = cv2.cvtColor(tmp_image, cv2.COLOR_RGB2BGR)
detection_result = self.bridge.cv2_to_imgmsg(tmp_image, &amp;quot;bgr8&amp;quot;)
self.detection_result_pub.publish(detection_result)
if __name__ == '__main__':
od = ObjectDetection()
try:
od.process()
except rospy.ROSInitException:
pass
&lt;/code>&lt;/pre>
&lt;p>コールバック関数で&lt;code>sensor_msgs/Image&lt;/code>型をnp.ndarray型に変換するために&lt;/p>
&lt;pre>&lt;code>cv_array = self.bridge.imgmsg_to_cv2(data, 'bgr8')
cv_array = cv2.cvtColor(cv_array, cv2.COLOR_BGR2RGB)
&lt;/code>&lt;/pre>
&lt;p>という&lt;code>sensor_msgs/Image&lt;/code>型特有の処理を行ってますが、Subscriberを作成しコールバック関数でデータを受け取るという基本的な処理の流れは&lt;code>scan&lt;/code>などの他のセンサと同じです。&lt;/p>
&lt;p>ここで注意してほしいのはYOLOの推論部分をコールバック関数内で行っていないことです。
一見、新しいデータが入ってくるときのみに推論を回すことは合理的に見えますが、センサの入力に対してコールバック関数内の処理が重いとセンサの入力がどんどん遅れていってしまいます。
コールバック関数内ではセンサデータの最低限の処理の記述にとどめ、重い処理は分けて書くことを意識しましょう。&lt;/p>
&lt;p>また、ここでは既存の物体検出モジュールを使用しましたが、PyTorchなどで作成した自作のモデルも同様の枠組みで利用することができます。&lt;/p>
&lt;p>続いて、RGB画像に整列されたデプス画像データを統合して物体を検出し、物体までの距離を測定してみましょう。&lt;/p>
&lt;p>RGB画像&lt;code>/camera/color/image_raw&lt;/code>と整列されたデプス画像&lt;code>/camera/aligned_depth_to_color/image_raw&lt;/code>はそれぞれ独立したトピックであるため、同期を取る必要があります。&lt;/p>
&lt;p>画像の同期にはmessage_filters(&lt;a href="http://wiki.ros.org/message_filters">http://wiki.ros.org/message_filters&lt;/a>)がよく使われます。&lt;/p>
&lt;p>message_filters.ApproximateTimeSynchronizerを使い以下のようにSubscriberを作成します。&lt;/p>
&lt;pre>&lt;code>rgb_sub = message_filters.Subscriber('/camera/color/image_raw', Image)
depth_sub = message_filters.Subscriber('/camera/aligned_depth_to_color/image_raw', Image)
message_filters.ApproximateTimeSynchronizer([rgb_sub, depth_sub], 10, 1.0).registerCallback(callback_rgbd)
def callback_rgbd(data1, data2):
bridge = CvBridge()
cv_array = bridge.imgmsg_to_cv2(data1, 'bgr8')
cv_array = cv2.cvtColor(cv_array, cv2.COLOR_BGR2RGB)
self.rgb_image = cv_array
cv_array = bridge.imgmsg_to_cv2(data2, 'passthrough')
self.depth_image = cv_array
&lt;/code>&lt;/pre>
&lt;p>この例では、1.0秒の許容で'/camera/color/image_raw&amp;rsquo;と'/camera/aligned_depth_to_color/image_raw&amp;rsquo;のトピックの同期を取ることができれば、コールバック関数callback_rgbdが呼ばれセンサデータが受けとられます。&lt;/p>
&lt;p>それでは、物体を検出し、物体までの距離を測定するスクリプトを見てみましょう。&lt;/p>
&lt;pre>&lt;code>#!/usr/bin/env python3
import rospy
import message_filters
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
from pytorchyolo import detect, models
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import cv2
import copy
class DetectionDistance:
def __init__(self):
rospy.init_node('detection_distance', anonymous=True)
# Publisher
self.detection_result_pub = rospy.Publisher('/detection_result', Image, queue_size=10)
# Subscriber
rgb_sub = message_filters.Subscriber('/camera/color/image_raw', Image)
depth_sub = message_filters.Subscriber('/camera/aligned_depth_to_color/image_raw', Image)
message_filters.ApproximateTimeSynchronizer([rgb_sub, depth_sub], 10, 1.0).registerCallback(self.callback_rgbd)
self.bridge = CvBridge()
self.rgb_image, self.depth_image = None, None
def callback_rgbd(self, data1, data2):
cv_array = self.bridge.imgmsg_to_cv2(data1, 'bgr8')
cv_array = cv2.cvtColor(cv_array, cv2.COLOR_BGR2RGB)
self.rgb_image = cv_array
cv_array = self.bridge.imgmsg_to_cv2(data2, 'passthrough')
self.depth_image = cv_array
def process(self):
path = &amp;quot;/root/roomba_hack/catkin_ws/src/three-dimensions_tutorial/yolov3/&amp;quot;
# load category
with open(path+&amp;quot;data/coco.names&amp;quot;) as f:
category = f.read().splitlines()
# prepare model
model = models.load_model(path+&amp;quot;config/yolov3.cfg&amp;quot;, path+&amp;quot;weights/yolov3.weights&amp;quot;)
while not rospy.is_shutdown():
if self.rgb_image is None:
continue
# inference
tmp_image = copy.copy(self.rgb_image)
boxes = detect.detect_image(model, tmp_image)
# [[x1, y1, x2, y2, confidence, class]]
# plot bouding box
for box in boxes:
x1, y1, x2, y2 = map(int, box[:4])
cls_pred = int(box[5])
tmp_image = cv2.rectangle(tmp_image, (x1, y1), (x2, y2), (0, 255, 0), 3)
tmp_image = cv2.putText(tmp_image, category[cls_pred], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
cx, cy = (x1+x2)//2, (y1+y2)//2
print(category[cls_pred], self.depth_image[cy][cx]/1000, &amp;quot;m&amp;quot;)
# publish image
tmp_image = cv2.cvtColor(tmp_image, cv2.COLOR_RGB2BGR)
detection_result = self.bridge.cv2_to_imgmsg(tmp_image, &amp;quot;bgr8&amp;quot;)
self.detection_result_pub.publish(detection_result)
if __name__ == '__main__':
dd = DetectionDistance()
try:
dd.process()
except rospy.ROSInitException:
&lt;/code>&lt;/pre>
&lt;p>基本的には物体検出のスクリプトと同じですが、&lt;/p>
&lt;pre>&lt;code>cx, cy = (x1+x2)//2, (y1+y2)//2
print(category[cls_pred], self.depth_image[cy][cx]/1000, &amp;quot;m&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>でbounding boxの中心座標を変換し、対応する距離をメートル単位で表示しています。&lt;/p>
&lt;p>整列されたデプス画像を用いているため、RGB画像に基づき算出した座標をそのまま指定できます。&lt;/p>
&lt;h3 id="点群の作成">点群の作成&lt;/h3>
&lt;p>上の例ではRGB画像とデプス画像を用いた三次元画像処理を行うことができました。&lt;/p>
&lt;p>しかし、ロボットの自立移動などより複雑な動作をさせることを考えたとき、深度データを三次元空間にマッピングできたほうが位置関係を統一的に扱うことができ便利なこともあります。&lt;/p>
&lt;p>それでデプス画像から点群と呼ばれるデータを作成することを考えます。&lt;/p>
&lt;p>点群とは三次元座標値(X,Y,Z)で構成された点の集まりのことです。各点の情報として、三次元座標値に加え色の情報(R,G,B)が加わることもあります。
デプス画像はカメラの内部パラメータを用いることによって点群データに変換することができます。(&lt;a href="https://medium.com/yodayoda/from-depth-map-to-point-cloud-7473721d3f">https://medium.com/yodayoda/from-depth-map-to-point-cloud-7473721d3f&lt;/a>)&lt;/p>
&lt;p>今回はdepth_image_procと呼ばれる、デプス画像を点群データに変換するROSの外部パッケージ(&lt;a href="http://wiki.ros.org/depth_image_proc">http://wiki.ros.org/depth_image_proc&lt;/a>) を使用して点群の変換を行います。&lt;/p>
&lt;p>外部パッケージは&lt;code>~/catkin_ws/src&lt;/code>等のワークスペースに配置し、ビルドしパスを通すことで簡単に使用できます。&lt;/p>
&lt;p>depth_image_procのwikiを参考に以下のようなlaunchファイルを作成しました。&lt;/p>
&lt;pre>&lt;code>&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;launch&amp;gt;
&amp;lt;node pkg=&amp;quot;nodelet&amp;quot; type=&amp;quot;nodelet&amp;quot; name=&amp;quot;nodelet_manager&amp;quot; args=&amp;quot;manager&amp;quot; /&amp;gt;
&amp;lt;node pkg=&amp;quot;nodelet&amp;quot; type=&amp;quot;nodelet&amp;quot; name=&amp;quot;nodelet1&amp;quot;
args=&amp;quot;load depth_image_proc/point_cloud_xyz nodelet_manager&amp;quot;&amp;gt;
&amp;lt;remap from=&amp;quot;camera_info&amp;quot; to=&amp;quot;/camera/color/camera_info&amp;quot;/&amp;gt;
&amp;lt;remap from=&amp;quot;image_rect&amp;quot; to=&amp;quot;/camera/aligned_depth_to_color/image_raw&amp;quot;/&amp;gt;
&amp;lt;remap from=&amp;quot;points&amp;quot; to=&amp;quot;/camera/depth/points&amp;quot;/&amp;gt;
&amp;lt;/node&amp;gt;
&amp;lt;/launch&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>このlaunchファイルを実行すると&lt;code>/camera/color/camera_info&lt;/code>と&lt;code>/camera/aligned_depth_to_color/image_raw&lt;/code>をSubscribeし、&lt;code>/camera/depth/points&lt;/code>をPublishします。&lt;/p>
&lt;p>&lt;code>/camera/color/camera_info&lt;/code>は&lt;code>sensor_msgs/CameraInfo&lt;/code>型のトピックであり、カメラパラメータやフレームid、タイムスタンプなどを保持しており、点群の変換に利用されます。
&lt;code>/camera/aligned_depth_to_color/image_raw&lt;/code>はRGB画像に整列されたデプス画像であるため、&lt;code>/camera/depth/camera_info&lt;/code>ではなく&lt;code>/camera/color/camera_info&lt;/code>を指定することに注意してください。&lt;/p>
&lt;p>&lt;code>roslaunch three-dimensions_tutorial depth2pc.launch&lt;/code>を行い&lt;code>/camera/depth/points&lt;/code>トピックをrvizで可視化をすると三次元空間に点群データが表示されているのが確認できます。&lt;/p>
&lt;h2 id="演習">演習&lt;/h2>
&lt;details class="spoiler " id="spoiler-0">
&lt;summary>(開発PC, jetson)起動準備&lt;/summary>
&lt;p>&lt;pre>&lt;code>(jetson)$ ./RUN-DOCKER-CONTAINER.sh
(jetson)(docker)# roslaunch roomba_bringup bringup.launch
(開発PC)$ ./RUN-DOCKER-CONTAINER.sh 192.168.10.7x
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-1">
&lt;summary>(開発PC)RealSenseのトピックの可視化&lt;/summary>
&lt;p>&lt;pre>&lt;code>(開発PC)(docker) rviz
&lt;/code>&lt;/pre>
&lt;p>&lt;code>/camera/color/image_raw&lt;/code>と&lt;code>/camera/depth/image_raw&lt;/code>と&lt;code>/camera/aligned_depth_to_color/image_raw&lt;/code>を可視化して違いを確認してみよう。&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-2">
&lt;summary>(開発PC)物体検出を行う&lt;/summary>
&lt;p>&lt;pre>&lt;code>(開発PC)(docker) cd catkin_ws; catkin_make; source devel/setup.bash
(開発PC)(docker) roscd three-dimensions_tutorial; cd yolov3/weights; ./download_weights.sh
(開発PC)(docker) rosrun three-dimensions_tutorial object_detection.py
rvizで`/detection_result`を表示し結果を確認してみよう。
(開発PC)(docker) rosrun three-dimensions_tutorial detection_distance.py
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-3">
&lt;summary>(開発PC)外部パッケージを使用&lt;/summary>
&lt;p>&lt;pre>&lt;code>(開発PC)(docker) cd ~/external_catkin_ws/src
(開発PC)(docker) git clone https://github.com/ros-perception/image_pipeline
(開発PC)(docker) cd ../; catkin build; source devel/setup.bash
(開発PC)(docker) cd ~/roomba_hack/catkin_ws; source devel/setup.bash
(開発PC)(docker) roslaunch three-dimensions_tutorial depth2pc.launch
(開発PC)(docker) roslaunch navigation_tutorial navigation.launch
&lt;/code>&lt;/pre>
&lt;p>rvizで&lt;code>/camera/depth/points&lt;/code>トピックを追加して確認してみよう。&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-4">
&lt;summary>余裕がある人向け&lt;/summary>
&lt;p>&lt;p>物体を検出し、特定の物体の手前まで移動するスクリプトを作ってみましょう。&lt;/p>
&lt;p>ヒント&lt;/p>
&lt;ul>
&lt;li>物体検出結果に基づいて物体部分以外をマスクしたデプス画像をpublishする&lt;/li>
&lt;li>depth2pc.launchでそれをsubscribeし、point(cloud)に変換する&lt;/li>
&lt;li>変換されたpointからmap座標系での位置を取得する&lt;/li>
&lt;li>navigation_tutorial/scripts/set_goal.py (map座標系で指定した位置・姿勢までナビゲーションするスクリプト)などを参考に、その位置へとナビゲーションする&lt;/li>
&lt;/ul>
&lt;p>PyTorchを使用した自作の分類器やネット上の分類器をシステムに組み込んでみましょう。&lt;/p>
&lt;p>Lidarに映らない物体も画像ベースで検出しコストマップに追加することでナビゲーション時にぶつからないようにしましょう。&lt;/p>
&lt;/p>
&lt;/details></description></item><item><title>自己位置推定</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap4/localization/</link><pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap4/localization/</guid><description>&lt;h2 id="learn">Learn&lt;/h2>
&lt;p>前回の演習では、オドメトリを用いてロボットを制御しました。&lt;/p>
&lt;!--1m進む、90度右回転など、ある程度正確に動いたかと思います。
しかし、これが数10m前進や、数分間動き続けた時にロボット自身は自分がスタートの時からどのくらい動いたかわかるでしょうか。-->
&lt;p>ルンバが用いているホイールオドメトリは、ホイールの回転量を足し合わせることで算出しています。
長い距離を動かしたり、長時間動かしているとセンサの僅かな誤差の積み重ねで徐々にずれが大きくなってしまいます。&lt;/p>
&lt;p>そこで今回は、オドメトリ情報だけでなく、地図とLiDARスキャン情報も同時に使いながら、ロボット自身の尤もらしい位置を推定していきましょう。&lt;/p>
&lt;h3 id="rosにおける座標系の扱い">ROSにおける座標系の扱い&lt;/h3>
&lt;details class="spoiler " id="spoiler-0">
&lt;summary>座標系を扱うモチベーション&lt;/summary>
&lt;p>ロボット頭部の距離画像カメラ（デプスカメラ）を用いて、2メートル前にりんごを見つけたとします。&lt;br>
この時、ロボットのハンドを2メートル前に動かしても、りんごに触れられるとは限りません。&lt;br>
ロボットには体積があり、各センサやアクチュエータ（ここではカメラとハンド）は距離的に離れているためです。&lt;br>
センサから得た情報を用いてロボットが何らかの動作を行うには、得たセンサの情報や動作の指令がどの座標系を前提としているのかを意識する必要があり、また、異なる座標系の変換を適切に行う必要があります。&lt;/p>
&lt;/details>
&lt;h4 id="tf">tf&lt;/h4>
&lt;p>&lt;a href="http://wiki.ros.org/tf2" target="_blank" rel="noopener">tf&lt;/a>は、&lt;/p>
&lt;ul>
&lt;li>ロボット座標系&lt;/li>
&lt;li>センサの座標系&lt;/li>
&lt;li>ロボットの関節の座標系&lt;/li>
&lt;li>部屋の座標系&lt;/li>
&lt;li>物体の座標系&lt;/li>
&lt;li>地図の座標系&lt;/li>
&lt;/ul>
&lt;p>など多くの座標系同士を繋げ、ロボットシステム上で座標系の管理をしてくれるROSのモジュールです。&lt;/p>
&lt;pre>&lt;code>$ rosrun rqt_tf_tree rqt_tf_tree
&lt;/code>&lt;/pre>
&lt;p>を実行すると、各座標系の間の関係を可視化することができます。&lt;br>
tfは、座標系の関係をツリー構造で管理します。親の座標系が複数あることは許されません。&lt;/p>
&lt;p>今回自己位置推定を行うにあたり用いる座標系の関係は以下のようになります。&lt;/p>
&lt;figure id="figure-tfツリーをrqtで可視化">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../rqt_tf_tree.png" alt="tfツリーをrqtで可視化" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
tfツリーをrqtで可視化
&lt;/figcaption>&lt;/figure>
&lt;p>ここで、odom座標系は、オドメトリの算出を始めた位置(起動した位置)を原点とした座標系で、
ホイールオドメトリの値から、ロボットの基準となるbase_footprint座標系を繋げています。
base_footprint座標系の下には、ルンバロボットの構成要素であるセンサ類やホイールなどの座標系が子として繋がっています。&lt;/p>
&lt;p>一番親にいるmap座標系は、地図の原点を基準とした座標系ですが、
この座標系におけるロボットの座標系(base_footprint)を繋げること、
つまり、ロボットが地図上のどこにいるのかを決めることが、
自己位置推定の目的になります。&lt;br>
今回の場合、base_footprintの親には既にodomがいるため、
map座標系とodom座標系を繋げることで、全体をひとつのツリーとして管理することができます。&lt;/p>
&lt;h3 id="自己位置推定">自己位置推定&lt;/h3>
&lt;p>自己位置推定は、地図が事前に与えられているという前提のもと、
その地図上のどこにロボットがいるのか、
外界センサ(LiDAR)と内界センサ(Odometry)を逐次的に用いて推定する手法です。&lt;/p>
&lt;p>多くの手法が存在しますが、ここでは、amcl(Adaptive Monte Carlo Localization)という方法について簡潔に説明します。
この手法は、&lt;/p>
&lt;ul>
&lt;li>sample_motion_model_odometry&lt;/li>
&lt;li>beam_range_finder_model&lt;/li>
&lt;li>likelishood_field_range_finder_model&lt;/li>
&lt;li>Augumented_MCL&lt;/li>
&lt;li>KLD_Sampling_MCL&lt;/li>
&lt;/ul>
&lt;p>などのアルゴリズムを用いていますが、自己位置推定のパッケージを使用するだけであれば、
これらのアルゴリズムの詳細をすべて理解する必要はありません。&lt;/p>
&lt;p>ロボットの姿勢は、地図座標系における位置と向きによって表されます。
amclはロボットがいると思われるこの姿勢の集合を保持しており、これらの姿勢はそれぞれ確率を持ちます。
確率が高くなるほど、そのロボットが実際にいそうな場所となります。&lt;/p>
&lt;p>センサ（LiDAR）からの信号は、それぞれの姿勢に対して、地図に沿って期待される信号と比較されます。
期待される信号と実際の信号の値の差が小さいほど、その姿勢の確率は高くなり、差が大きくなるとその姿勢の確率は低くなります。
時間が経過すると、低い確率の姿勢は消えていき、高い確率を持つものが残ります。
ロボットが世界を動き回ると、候補となる姿勢はロボットのオドメトリの推定に従って、ロボットと共に移動します。&lt;/p>
&lt;!--
- ヒストグラムフィルタ
- カルマンフィルタ
- パーティクルフィルタ
などいくつかの手法が存在し、それぞれメリットデメリットがありますが、
ここでは代表的なパーティクルフィルタを用いた手法を紹介します。
自己位置推定では、観測モデルと状態遷移モデルを交互に繰り返すことによって、
ロボット自身がどこにいるかの確率分布を更新していくことで自己位置推定をしていきます。
パーティクルフィルタでは、この確率分布を大量の粒子を用いて表現する手法になっていて、
各粒子が位置とそこにロボットがいるであろう確率(尤度)を持っています。
ロボットが動くごと(オドメトリが更新されるごと)に、
状態遷移モデルを用いて各粒子の位置情報を更新します。
この時、一般的に分布は広がります。
(人間が目を閉じて歩いたらどこにいるか分かりづらくなるのと同じ)
外界の情報がわかるごと(スキャン情報が更新されるごと)に、
観測モデルを用いて各粒子の尤度を更新します。
尤度は、各粒子の位置から観測できるであろうスキャン情報と、
実際のロボットで取得したスキャン情報との差から算出します。
-->
&lt;figure id="figure-monte-carlo-localizationparticle-filter-dieter-fox-et-al-1999-using-sonar-httpwwwdocicacukajdroboticsroboticsresourcesmontecarlolocalizationgif">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../montecarlolocalization.gif" alt="Monte Carlo Localization(Particle Filter) Dieter Fox et al. 1999, using sonar. http://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/montecarlolocalization.gif" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Monte Carlo Localization(Particle Filter) Dieter Fox et al. 1999, using sonar. &lt;a href="http://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/montecarlolocalization.gif">http://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/montecarlolocalization.gif&lt;/a>
&lt;/figcaption>&lt;/figure>
&lt;!-- リサンプリング -->
&lt;p>[詳しい文献]&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Probabilistic Robotics&amp;rdquo; by Sebastian Thrun, Wolfram Burgard, Dieter Fox
&lt;ul>
&lt;li>邦訳：&amp;ldquo;確率ロボティクス&amp;rdquo; 上田隆一&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="launchファイルとrosparam">launchファイルとrosparam&lt;/h3>
&lt;p>自己位置推定では、初期位置がどこか、レーザーのスペックや、パーティクルの数など数十個のパラメータを保持します。&lt;/p>
&lt;p>これらをプログラム内部で記述するのではなく、launchファイル内で指定することが可能です。
rosでは、rosparamという形でパラメータを管理することが可能です。&lt;/p>
&lt;p>以下に、今回用いる&lt;code>amcl.launch&lt;/code> を示します。
launchファイルはxml形式で記述され、paramを指定すること以外にも、
launchファイル実行時に引数で指定可能なargや、トピック名などのリマップをすることも可能です。&lt;/p>
&lt;p>launchの詳しい書き方は、&lt;a href="http://wiki.ros.org/ja/roslaunch/XML" target="_blank" rel="noopener">rosのドキュメント&lt;/a>を参照してください。&lt;/p>
&lt;pre>&lt;code class="language-xml">&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;launch&amp;gt;
&amp;lt;arg name=&amp;quot;use_map_topic&amp;quot; default=&amp;quot;true&amp;quot;/&amp;gt;
&amp;lt;arg name=&amp;quot;odom_topic&amp;quot; default=&amp;quot;/odom&amp;quot; /&amp;gt;
&amp;lt;arg name=&amp;quot;scan_topic&amp;quot; default=&amp;quot;/scan&amp;quot; /&amp;gt;
&amp;lt;node pkg=&amp;quot;amcl&amp;quot; type=&amp;quot;amcl&amp;quot; name=&amp;quot;amcl&amp;quot; output=&amp;quot;screen&amp;quot;&amp;gt;
&amp;lt;remap from=&amp;quot;scan&amp;quot; to=&amp;quot;$(arg scan_topic)&amp;quot;/&amp;gt;
&amp;lt;remap from=&amp;quot;odom&amp;quot; to=&amp;quot;$(arg odom_topic)&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;use_map_topic&amp;quot; value=&amp;quot;$(arg use_map_topic)&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;initial_pose_x&amp;quot; value=&amp;quot;0.0&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;initial_pose_y&amp;quot; value=&amp;quot;0.0&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;initial_pose_a&amp;quot; value=&amp;quot;0.0&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;initial_cov_xx&amp;quot; value=&amp;quot;0.1*0.1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;initial_cov_yy&amp;quot; value=&amp;quot;0.1*0.1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;initial_cov_aa&amp;quot; value=&amp;quot;0.3*3.14&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;gui_publish_rate&amp;quot; value=&amp;quot;10.0&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_max_beams&amp;quot; value=&amp;quot;2.0&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_min_range&amp;quot; value=&amp;quot;0.15&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_max_range&amp;quot; value=&amp;quot;12.0&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_z_hit&amp;quot; value=&amp;quot;0.8&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_z_short&amp;quot; value=&amp;quot;0.1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_z_max&amp;quot; value=&amp;quot;0.1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_z_rand&amp;quot; value=&amp;quot;0.1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_sigma_hit&amp;quot; value=&amp;quot;0.2&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_lambda_short&amp;quot; value=&amp;quot;0.1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_model_type&amp;quot; value=&amp;quot;likelihood_field&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;laser_likelihood_max_dist&amp;quot; value=&amp;quot;2.0&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;min_particles&amp;quot; value=&amp;quot;100&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;max_particles&amp;quot; value=&amp;quot;1000&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;kld_err&amp;quot; value=&amp;quot;0.0&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;kld_z&amp;quot; value=&amp;quot;0.0&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;update_min_d&amp;quot; value=&amp;quot;0.1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;update_min_a&amp;quot; value=&amp;quot;0.1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;resample_interval&amp;quot; value=&amp;quot;1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;transform_tolerance&amp;quot; value=&amp;quot;0.2&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;recovery_alpha_slow&amp;quot; value=&amp;quot;0.001&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;recovery_alpha_fast&amp;quot; value=&amp;quot;0.1&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;odom_frame_id&amp;quot; value=&amp;quot;odom&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;odom_model_type&amp;quot; value=&amp;quot;diff&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;odom_alpha1&amp;quot; value=&amp;quot;0.2&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;odom_alpha2&amp;quot; value=&amp;quot;0.2&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;odom_alpha3&amp;quot; value=&amp;quot;0.2&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;odom_alpha4&amp;quot; value=&amp;quot;0.2&amp;quot;/&amp;gt;
&amp;lt;param name=&amp;quot;odom_alpha5&amp;quot; value=&amp;quot;0.2&amp;quot;/&amp;gt;
&amp;lt;/node&amp;gt;
&amp;lt;/launch&amp;gt;
&lt;/code>&lt;/pre>
&lt;h2 id="演習">演習&lt;/h2>
&lt;details class="spoiler " id="spoiler-3">
&lt;summary>【jetson・開発マシン】それぞれdockerコンテナを起動&lt;/summary>
&lt;p>&lt;p>jetsonでdockerコンテナを起動&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC):~$ ssh roomba_dev1
(jetson):~$ cd ~/group_a/roomba_hack
(jetson)::~/group_a/roomba_hack$ git pull
(jetson):~/group_a/roomba_hack$ ./RUN-DOCKER-CONTAINER.sh
(jetson)(docker):~/roomba_hack# roslaunch roomba_bringup bringup.launch
&lt;/code>&lt;/pre>
&lt;p>開発PCでdockerコンテナを起動&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC):~$ cd ~/group_a/roomba_hack
(開発PC):~/group_a/roomba_hack$ git pull
(開発PC):~/group_a/roomba_hack$ ./RUN-DOCKER-CONTAINER.sh 192.168.10.7x
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-4">
&lt;summary>gmappingで地図作成&lt;/summary>
&lt;p>&lt;pre>&lt;code>(開発PC)(docker) roslaunch navigation_tutorial gmapping.launch
&lt;/code>&lt;/pre>
&lt;p>地図の保存。map.pgm（画像データ）とmap.yaml(地図情報)が保存される。&lt;/p>
&lt;pre>&lt;code>(開発PC)(docker) rosrun map_server map_saver
&lt;/code>&lt;/pre>
&lt;p>&lt;code>~/roomba_hack/catkin_ws/src/navigation_tutorial/map&lt;/code> の下に保存する。&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-5">
&lt;summary>amclをlaunchして、自己位置推定する&lt;/summary>
&lt;p>&lt;p>localizationノードと地図サーバーを同時に起動。&lt;/p>
&lt;pre>&lt;code>(開発PC)(docker) roslaunch navigation_tutorial localization.launch
(開発PC)(docker) roslaunch roomba_teleop teleop.launch
(開発PC)(docker) rviz -d /root/roomba_hack/catkin_ws/src/navigation_tutorial/configs/navigation.rviz
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>初期位置の指定(rvizの2D Pose Estimate)&lt;/li>
&lt;li>コントローラで移動させてみて自己位置を確認&lt;/li>
&lt;li>rqt_tf_treeを見てみる&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-6">
&lt;summary>amclのparamをチューニングする&lt;/summary>
&lt;p>&lt;p>launchファイルの中身を見てみて、値を変えてみる。&lt;/p>
&lt;p>各パラメータの意味は&lt;a href="https://wiki.ros.org/amcl#Parameters">amclのページ&lt;/a>を参照。&lt;/p>
&lt;p>例えば、・・・&lt;/p>
&lt;ul>
&lt;li>initial_cov_** を大きくしてみて、パーティクルがちゃんと収束するかみてみる。&lt;/li>
&lt;li>particleの数(min_particles、max_particles)を変えてみて挙動をみてみる。&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-7">
&lt;summary>launchファイルの拡張&lt;/summary>
&lt;p>&lt;p>localization.launchファイルに以下を追加してteleop.launchとrvizが同時に起動するようにしてみよう。&lt;/p>
&lt;pre>&lt;code>&amp;lt;!-- teleop.launchを起動--&amp;gt;
&amp;lt;include file=&amp;quot;$(find roomba_teleop)/launch/teleop.launch&amp;quot;&amp;gt;
&amp;lt;/include&amp;gt;
&amp;lt;!-- rvizを起動--&amp;gt;
&amp;lt;node pkg=&amp;quot;rviz&amp;quot; type=&amp;quot;rviz&amp;quot; name=&amp;quot;navigation_rviz&amp;quot; args=&amp;quot;-d $(find navigation_tutorial)/configs/navigation.rviz&amp;quot;/&amp;gt;
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details></description></item><item><title>ロボットシステムにおけるセンシング・アクチュエーション・通信③</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap3/sensing3/</link><pubDate>Thu, 22 Jun 2023 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap3/sensing3/</guid><description>&lt;p>複数のセンサを組み合わせてよりかしこくロボットを動かしてみよう&lt;/p>
&lt;h2 id="learn">Learn&lt;/h2>
&lt;h3 id="lidarのスキャンデータを使って障害物を回避してみよう">LiDARのスキャンデータを使って，障害物を回避してみよう&lt;/h3>
&lt;p>次に，LiDARでスキャンしたデータを使って，障害物を回避するようなプログラムを作ってみましょう．&lt;/p>
&lt;h4 id="lidarスキャンのメッセージscanの中身を見てみよう">LiDARスキャンのメッセージ（&lt;code>/scan&lt;/code>）の中身を見てみよう&lt;/h4>
&lt;p>LiDARは，Light Detection And Rangingの略で，レーザ光を使って離れた場所にある物体形状や距離を測定するためのセンサです．
近年では，自動車の自動運転にも用いられることの多いセンサの一つです．&lt;/p>
&lt;p>roombaに搭載されたLiDARセンサ（rplidar）の値は，&lt;code>/scan&lt;/code>のトピックに流れていて，&lt;code>rostopic echo /scan&lt;/code>をしてみるとメッセージとしてどんな情報が流れているかわかります．&lt;/p>
&lt;p>大きなデータなので今回はテキストに掲載するのは省略しますが，&lt;code>rostopic type /scan&lt;/code>をしてみると，メッセージとして，&lt;code>sensor_msgs/LaserScan&lt;/code>型が使われていることがわかります．
&lt;details class="spoiler " id="spoiler-0">
&lt;summary>&lt;code>rostopic type /scan&lt;/code>&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-bash">root@dynamics:~/roomba_hack# rostopic type /scan
sensor_msgs/LaserScan
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>&lt;/p>
&lt;p>&lt;code>sensor_msgs/LaserScan&lt;/code>型の定義を確認してみましょう．
メッセージ型の定義は，&lt;a href="http://docs.ros.org/en/melodic/api/sensor_msgs/html/msg/LaserScan.html" target="_blank" rel="noopener">ドキュメント&lt;/a>のほか，&lt;code>rosmsg info sensor_msgs/LaserScan&lt;/code>することでもコマンドから確認できます．
&lt;details class="spoiler " id="spoiler-1">
&lt;summary>&lt;code>rosmsg info sensor_msgs/LaserScan&lt;/code>&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-bash">root@dynamics:~/roomba_hack# rosmsg info sensor_msgs/LaserScan
std_msgs/Header header
uint32 seq
time stamp
string frame_id
float32 angle_min
float32 angle_max
float32 angle_increment
float32 time_increment
float32 scan_time
float32 range_min
float32 range_max
float32[] ranges
float32[] intensities
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>&lt;/p>
&lt;p>&lt;code>angle_min&lt;/code>にはスキャンの開始角度，&lt;code>angle_max&lt;/code>にはスキャンの終了角度がラジアンで記録されています．
&lt;code>angle_increment&lt;/code>は，計測した間隔がラジアンで記録されています．
&lt;code>range_max&lt;/code>にはスキャンの間で検出された最大の距離，&lt;code>range_min&lt;/code>には最小の距離がメートルで記録されています．&lt;/p>
&lt;h4 id="rvizでlidarスキャンの値を可視化してみよう">rvizでLiDARスキャンの値を可視化してみよう&lt;/h4>
&lt;p>rvizでLiDARのスキャン結果を可視化してみましょう．&lt;/p>
&lt;p>&lt;code>LaserScan&lt;/code>をAddして，&lt;code>topic&lt;/code>に&lt;code>/scan&lt;/code>を設定すると，以下のように，ロボットを中心にLiDARによって計測された障害物が赤く表示されます．&lt;/p>
&lt;figure id="figure-lidarスキャンをrvizで可視化">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../lidar_scan.png" alt="LiDARスキャンをrvizで可視化" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
LiDARスキャンをrvizで可視化
&lt;/figcaption>&lt;/figure>
&lt;h4 id="lidarを使って障害物を回避しよう">LiDARを使って障害物を回避しよう&lt;/h4>
&lt;p>それでは，LiDARスキャン&lt;code>/scan&lt;/code>の情報を使った制御の実装の例として&lt;code>navigation_tutorial&lt;/code>パッケージの中の&lt;a href="https://github.com/matsuolab/roomba_hack/blob/master/catkin_ws/src/navigation_tutorial/scripts/avoidance.py" target="_blank" rel="noopener">avoidance.py&lt;/a>をみてみましょう．&lt;/p>
&lt;details class="spoiler " id="spoiler-3">
&lt;summary>avoidance.py&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-python">#!/usr/bin/env python3
import numpy as np
import rospy
from geometry_msgs.msg import Twist
from sensor_msgs.msg import LaserScan
class Avoidance:
def __init__(self):
rospy.init_node('avoidance', anonymous=True)
# Publisher
self.cmd_vel_pub = rospy.Publisher('/planner/cmd_vel', Twist, queue_size=10)
# Subscriber
scan_sub = rospy.Subscriber('/scan', LaserScan, self.callback_scan)
self.min_range = None
def callback_scan(self, data):
fov = np.deg2rad(60)
min_range = data.range_max
min_idx = -1
angle = data.angle_min
for idx, r in enumerate(data.ranges):
angle += data.angle_increment
if -fov&amp;lt;angle&amp;lt;fov:
if r&amp;lt;min_range:
min_range = r
min_idx = idx
if min_idx &amp;lt; len(data.ranges)/2.0:
self.direction = &amp;quot;RIGHT&amp;quot;
else:
self.direction = &amp;quot;LEFT&amp;quot;
self.min_range = min_range
def process(self):
r = rospy.Rate(10)
while not rospy.is_shutdown():
vel = Twist()
if self.min_range is not None:
if self.min_range &amp;gt;= 0.4:
vel.linear.x = 0.2
vel.angular.z = 0.0
else:
vel.linear.x = 0.0
if self.direction == &amp;quot;RIGHT&amp;quot;:
vel.angular.z = 0.5
elif self.direction == &amp;quot;LEFT&amp;quot;:
vel.angular.z = -0.5
self.cmd_vel_pub.publish(vel)
r.sleep()
if __name__=='__main__':
avoidance = Avoidance()
try:
avoidance.process()
except rospy.ROSInitException:
pass
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;p>このプログラムでは，LiDARを使って進行方向に存在する障害物を見つけ，それを回避しながら進むようにロボットを制御しています．具体的には，&lt;/p>
&lt;ul>
&lt;li>ロボットの進行方向に物体がなかったら直進&lt;/li>
&lt;li>ロボットの右側に障害物があったら左回転&lt;/li>
&lt;li>ロボットの左側に障害物があったら右回転&lt;/li>
&lt;/ul>
&lt;p>することで障害物を回避（ぶつかる前に方向転換）しています．&lt;/p>
&lt;p>では，プログラムの中身を見ていきます．&lt;/p>
&lt;p>&lt;a href="../sensing2/">&lt;code>/odom&lt;/code>を使った制御の場合&lt;/a>と同様に，ノードを定義する際に，コマンドを送るパブリッシャと，LiDARスキャンのデータを読み取るサブスクライバを作成します．&lt;/p>
&lt;pre>&lt;code class="language-python">class Avoidance:
def __init__(self):
rospy.init_node('avoidance', anonymous=True)
# Publisher
self.cmd_vel_pub = rospy.Publisher('/planner/cmd_vel', Twist, queue_size=10)
# Subscriber
scan_sub = rospy.Subscriber('/scan', LaserScan, self.callback_scan)
self.min_range = None
&lt;/code>&lt;/pre>
&lt;p>&lt;code>/scan&lt;/code>のコールバックは，&lt;/p>
&lt;pre>&lt;code class="language-python"> def callback_scan(self, data):
fov = np.deg2rad(60)
min_range = data.range_max
min_idx = -1
angle = data.angle_min
for idx, r in enumerate(data.ranges):
angle += data.angle_increment
if -fov&amp;lt;angle&amp;lt;fov:
if r&amp;lt;min_range:
min_range = r
min_idx = idx
if min_idx &amp;lt; len(data.ranges)/2.0:
self.direction = &amp;quot;RIGHT&amp;quot;
else:
self.direction = &amp;quot;LEFT&amp;quot;
self.min_range = min_range
&lt;/code>&lt;/pre>
&lt;p>となっており，正面から左右60度の範囲内で最も短い距離を&lt;code>self.min_range&lt;/code>に格納し，それが右側にあるのか左側にあるのかを&lt;code>self.direction&lt;/code>に格納しています．．&lt;/p>
&lt;p>このプログラムを実行すると&lt;code>process&lt;/code>メソッドが（0.1秒おきに）常に実行されます．&lt;/p>
&lt;pre>&lt;code class="language-python"> def process(self):
r = rospy.Rate(10)
while not rospy.is_shutdown():
vel = Twist()
if self.min_range is not None:
if self.min_range &amp;gt;= 0.4:
vel.linear.x = 0.2
vel.angular.z = 0.0
else:
vel.linear.x = 0.0
if self.direction == &amp;quot;RIGHT&amp;quot;:
vel.angular.z = 0.5
elif self.direction == &amp;quot;LEFT&amp;quot;:
vel.angular.z = -0.5
self.cmd_vel_pub.publish(vel)
r.sleep()
&lt;/code>&lt;/pre>
&lt;p>&lt;code>process&lt;/code>メソッド内部では，格納された&lt;code>self.min_range&lt;/code>が0.4（メートル）より大きい場合は，ロボットの前に何もないと判断して直進，小さい場合は，&lt;code>self.direction&lt;/code>の値を見て，&lt;code>RIGHT&lt;/code>であれば右に障害物があると判断して左回転，&lt;code>LEFT&lt;/code>であれば左に障害物があると判断して右回転するようなプログラムになっています．&lt;/p>
&lt;p>それでは，実際にLiDARを使って障害物を回避するプログラムを実行してみましょう．&lt;/p>
&lt;h2 id="演習">演習&lt;/h2>
&lt;details class="spoiler " id="spoiler-4">
&lt;summary>【開発PC】topicの確認&lt;/summary>
&lt;p>&lt;p>&lt;code>/scan&lt;/code>の型を確認&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker):~/roomba_hack# rostopic type /scan
&lt;/code>&lt;/pre>
&lt;p>&lt;code>/scan&lt;/code>の中身を確認&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker):~/roomba_hack# rostopic echo /scan
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-5">
&lt;summary>LiDARスキャンを使ったフィードバック制御&lt;/summary>
&lt;p>&lt;p>&lt;code>avoidance.py&lt;/code>を実行してみよう．&lt;/p>
&lt;p>このプログラムを動かすときには，コントローラの&lt;code>Y&lt;/code>ボタンを押してから&lt;code>B&lt;/code>ボタンを押して&lt;code>auto&lt;/code>モードにしておきましょう．&lt;/p>
&lt;p>今回はせっかくなので，launchfileから起動してみましょう．
このlaunchfileは，&lt;code>navigation_tutorial&lt;/code>パッケージの中の&lt;code>launch&lt;/code>フォルダの中にある&lt;code>avoidance.launch&lt;/code>に記述されています（&lt;a href="https://github.com/matsuolab/roomba_hack/blob/master/catkin_ws/src/navigation_tutorial/launch/avoidance.launch">github&lt;/a>）．&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker):~/roomba_hack# roslaunch navigation_tutorial avoidance.launch
&lt;/code>&lt;/pre>
&lt;p>ロボットの進行方向に障害物があるときに，それを避けるように方向転換したら成功です．&lt;/p>
&lt;p>try it! &lt;code>avoidance.py&lt;/code>の中身を読んでコードを変更してみよう&lt;/p>
&lt;/p>
&lt;/details></description></item><item><title>ROSとは</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap1/ros/</link><pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap1/ros/</guid><description>&lt;p>ロボット開発によく用いられるROSの概要を理解する&lt;/p>
&lt;h2 id="learn">Learn&lt;/h2>
&lt;h3 id="rosの概要">ROSの概要&lt;/h3>
&lt;p>ROS(Robot Operating System)は、ロボット・アプリケーション開発に便利な機能を提供するフレームワークです。
フレームワークとは、プログラミング言語を特定の目的に特化させて使うためのツールのことです。
具体的には以下にあげる機能を提供しています。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>メッセージ通信&lt;/p>
&lt;ul>
&lt;li>プロセス間、コンピュータ間の通信ライブラリが提供されています。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>デバイスドライバ&lt;/p>
&lt;ul>
&lt;li>
&lt;p>ROSに対応しているセンサやアクチュエータを搭載したロボットであれば、違うロボットであってもほぼ同じソースコードを使用して動かすことができます。&lt;br>
roombaを動かすために書いたソースコードをそのまま使用してHSRを動かす、といったことができます。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/ros-drivers">https://github.com/ros-drivers&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://wiki.ros.org/Sensors">http://wiki.ros.org/Sensors&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>ライブラリ&lt;/p>
&lt;ul>
&lt;li>ロボットを動作させるソフトウェア(ナビゲーション、マニピュレーション)の基本機能の大半が提供されています。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>視覚化ツール&lt;/p>
&lt;ul>
&lt;li>ロボットの内部状態やセンサ出力を2次元、3次元で視覚化するRvizや3次元動力学シミュレータのGazeboなどが提供されています。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>パッケージ管理&lt;/p>
&lt;ul>
&lt;li>多種多様なプログラミング言語(python, C++, &amp;hellip;)、依存関係で記述されたプログラム同士を統合的に使用することが可能です。&lt;/li>
&lt;li>これにより、経路計画など処理が重いプロセスはC++でコードを書き、画像認識など機械学習系のプロセスはpythonでコードを書く、といったこともできるようになります。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="rosのメッセージ通信">ROSのメッセージ通信&lt;/h3>
&lt;p>ロボットを動かす際には、多くのプログラムを並列して実行し、それぞれがデータをやりとりする必要があります。
ROSはそのようなプログラム間の通信に必要な機能を提供しています。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>ノード(node)&lt;/p>
&lt;ul>
&lt;li>ROSでは、一つのプログラム単位を「ノード(node)」と呼びます。&lt;/li>
&lt;li>基本的には、一つのファイルが一つのノードに対応しています。&lt;/li>
&lt;li>各ノードは次に述べるtopic、service、actionlibの三つの通信方法を使って、他のノードとデータのやり取りを行います。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>トピック(topic)&lt;/p>
&lt;ul>
&lt;li>
&lt;p>ROSでの、最も基本的なデータ通信の経路を「トピック(topic)」と呼びます。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ノードはメッセージをトピックへ向けて配信(Publish)し、また購読する(Subscribe)ことで他のノードと情報を共有することができます。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>配信を行うノードをPublisher、購読を行うノードをSubscriberと呼びます。ノードはこのどちらかに二分することができるというわけではなく、実際には一つのノードがpublisherであり、subscriberでもあるという状況がほとんどです。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>トピックには名前が付けられており、同じトピックに複数のノードがデータを送ったり、複数のノードが同じデータを受け取ることができます。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>メッセージ(message)&lt;/p>
&lt;p>トピックへ配信したり、購読したりするときのROSのデータ型のことを「メッセージ(message)」と呼びます。
メッセージの型はmsgファイルに記述されており、使用するプログラミング言語に依存しないデータ形式になっています。&lt;/p>
&lt;p>以下に、物体やロボットの位置を表す時によく用いる&lt;code>geomemtry_msgs/PoseStamped&lt;/code>型のmsgファイルを示します。
位置情報の時間や座標フレームの情報が含まれるheaderと座標位置を表すposeで定義されています。&lt;/p>
&lt;pre>&lt;code>std_msgs/Header header
uint32 seq
time stamp
string frame_id
geometry_msgs/Pose pose
geometry_msgs/Point position
float64 x
float64 y
float64 z
geometry_msgs/Quaternion orientation
float64 x
float64 y
float64 z
float64 w
&lt;/code>&lt;/pre>
&lt;p>各行の左側にはデータ型が、右側には変数名が記述されています。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Topic通信のイメージ
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../node.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>サービス(service)&lt;/p>
&lt;ul>
&lt;li>
&lt;p>「サービス(service)」も、ノードが他のノードと通信するための手段の一つです。topicより少し複雑な通信の仕方を提供します.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>サービスには、サービスを提供するノード（service server）とサービスを要求するノード(service client)があります。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>サービスは以下のような流れで使用されます。&lt;/p>
&lt;ol>
&lt;li>clientがserverに引数を渡す。&lt;/li>
&lt;li>引数を受け取ったserverが何らかのプログラムを実行する。&lt;/li>
&lt;li>serverは行為の結果を返り値としてclientに返す。&lt;/li>
&lt;li>clientはその返り値に応じて後の挙動を変える。&lt;/li>
&lt;/ol>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../ros_service.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>サービスにおいて送受信されるデータの型は.srvファイルに記述されています。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>メッセージと同様使用言語に依存しないデータ形式ですが、メッセージと異なるのは、引数と戻り値の二つの形式を定義する必要があるところです。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>以下に、srvの例として&lt;code>std_srvs/SetBool&lt;/code>を示します。&lt;br>
このように引数と戻り値の間に&lt;code>---&lt;/code>を入れて定義します。&lt;/p>
&lt;pre>&lt;code>bool data
---
bool success
string message
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>アクション(actionlib)&lt;/p>
&lt;ul>
&lt;li>アクションもノード間通信の一つの手段です。serviceよりもさらに複雑な通信ができます。&lt;/li>
&lt;li>サービスは動作の終了時にのみserverからclientに結果を返すのに対し、アクションは動作の途中経過をclientに渡すことができます。&lt;/li>
&lt;li>ここでは詳しい説明を省略します。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>ROSマスタ(ROS master)&lt;/p>
&lt;ul>
&lt;li>
&lt;p>「ROSマスタ(ROS master)」は、ノード、トピックおよびサービスの名前登録を行い、それぞれのノードが他のノードから見えるようにする役割を担っています。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通信するノード名とトピック名およびサービス名の対応が決定した後、ノード同士が「peer-to-peer」で通信します。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ROSマスタを起動するには「roscore」というコマンドを実行します（が、RoombaやHSRをつかうときにはこのコマンドが自動で実行されることが多いため、あまり意識する機会はないかもしれません）。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!--
パラメータサーバは必須ではないと思うのでコメントアウト。
- パラメータサーバ(parameter server)
「パラメータサーバ(parameter server)」は、設定データを複数のノードで共有するための軽量なサーバです。
各ノードのパラメータを、パラメータサーバで一括して管理できます。
パラメータサーバもROSマスタ同様に「roscore」コマンドで起動します。
パラメータサーバで扱える型は、整数・小数・真偽値・辞書・リストになります。
-->
&lt;!--
- ROSのデータ通信のまとめ
&lt;figure id="figure-ros通信">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../ros_communication.png" alt="ROS通信" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
ROS通信
&lt;/figcaption>&lt;/figure>
-->
&lt;h3 id="rosと連動するソフトウェア">ROSと連動するソフトウェア&lt;/h3>
&lt;p>ROSは以下のようなソフトウェアと連動して使うためのパッケージを提供しています。簡単な説明にとどめるので、詳しい使い方は必要になった際に調べてください。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>OpenCV&lt;/p>
&lt;p>豊富な機能を持つ2D画像処理用のライブラリです。
カメラで撮影した画像を処理する際に使用します。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>PCL(Point Cloud Library)&lt;/p>
&lt;ul>
&lt;li>3次元点群処理のライブラリ。&lt;/li>
&lt;li>HSRやRoombaにはRGBDカメラが搭載されています。DはDepthという意味で、画像の各ピクセルに距離情報を対応させたDepth画像を取得することができます。&lt;br>
このような三次元の点群の情報を処理する際にPCLを使うと便利です。&lt;/li>
&lt;/ul>
&lt;!--OpenCV同様PCLのデータ形式とROSのメッセージ形式を変換するパッケージが提供されています。-->
&lt;/li>
&lt;li>
&lt;p>OpenSLAM&lt;/p>
&lt;ul>
&lt;li>地図を効果的に使うことで、より安定したロボットのナビゲーションを行うことができます。&lt;/li>
&lt;li>移動ロボットの自己位置推定と地図生成を同時に行うSLAM(Simultaneous Localization and Mapping)という手法は、それだけで一つの研究分野になる程奥深い分野で、活発に研究が行われています。&lt;/li>
&lt;li>OpenSLAMは、SLAMのソースコードを公開するためのプラットフォームを提供しており、様々なSLAMの手法を実装しています。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!--
roombaには手がついていないので、MoveIt!の説明は省略。
- **Move it**
-->
&lt;p>これ以外にも多くのツールがROSと連動しています。&lt;/p>
&lt;h3 id="可視化ツール">可視化ツール&lt;/h3>
&lt;p>ロボット内部の大量のデータが正しく処理されているか知りたい場合、変数の中身の数値などを直接みるのは大変です。直感的にわかりづらいためミスも増えます。&lt;br>
可視化をすることで、開発やデバッグがより効率よく進められます。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>rqt&lt;/p>
&lt;p>rqtはROSのGUIフレームワークで、様々なツールを提供しています。&lt;br>
ノードの状態を可視化する&lt;code>rqt_graph&lt;/code>(下図1)、メッセージの値を時系列に沿ってプロットする&lt;code>rqt_plot&lt;/code>(下図2)などがあります。&lt;/p>
&lt;figure id="figure-図1-rqt_graph-wikipediahttpwikirosorgrqt_graphより引用">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../rqt_graph.png" alt="図1 rqt_graph [wikipedia](http://wiki.ros.org/rqt_graph)より引用" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
図1 rqt_graph &lt;a href="http://wiki.ros.org/rqt_graph">wikipedia&lt;/a>より引用
&lt;/figcaption>&lt;/figure>
&lt;figure id="figure-図2-rqt_plot-wikipediahttpwikirosorgrqt_plotより引用">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../rqt_plot.png" alt="図2 rqt_plot [wikipedia](http://wiki.ros.org/rqt_plot)より引用" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
図2 rqt_plot &lt;a href="http://wiki.ros.org/rqt_plot">wikipedia&lt;/a>より引用
&lt;/figcaption>&lt;/figure>
&lt;/li>
&lt;/ul>
&lt;!-- http://wiki.ros.org/rqt -->
&lt;ul>
&lt;li>
&lt;p>RViz&lt;/p>
&lt;p>ロボットの三次元モデルや座標系、測定した三次元点群などを可視化するツールです。&lt;br>
三次元空間の情報以外に、カメラに写っている画像なども表示できます。&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/i--Sd4xH9ZE" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;!-- http://wiki.ros.org/ja/rviz -->
&lt;/li>
&lt;li>
&lt;p>gazebo&lt;/p>
&lt;p>オープンソースのロボット用三次元動力学シミュレータ。&lt;br>
説明は割愛します。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;!-- ### パッケージ管理
- プログラミング言語
- rosdep
- -->
&lt;h2 id="演習">演習&lt;/h2>
&lt;details class="spoiler " id="spoiler-6">
&lt;summary>roombaドライバを起動し、動作することを確認する&lt;/summary>
&lt;p>&lt;ol>
&lt;li>
&lt;p>jetsonにアクセスする&lt;/p>
&lt;pre>&lt;code class="language-sh">(開発PC):~$ ssh roomba_dev1
(jetson):~$
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>dockerコンテナを起動する&lt;/p>
&lt;!--余裕があれば`RUN-DOCKER-CONTAINER.sh`ファイルの中身を確認してみましょう。-->
&lt;pre>&lt;code class="language-sh">(jetson):~$ cd ~/23_group_x/roomba_hack
(jetson):~/23_group_x/roomba_hack$ ./RUN-DOCKER-CONTAINER.sh
# このファイルを実行することでdockerコンテナを作成し、コンテナの中に入る。
root@roomba-dev-jetson:~/roomba_hack#
# 上のように表示されればコンテナ内部に入れています。
&lt;/code>&lt;/pre>
&lt;p>今後docker内部であることは(docker)と表記します。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>roomba driverなどを起動するlaunchファイルを実行する&lt;br>
このタイミングでルンバの電源が入っているかを確認しておきましょう。&lt;/p>
&lt;pre>&lt;code class="language-sh">(jetson)(docker):~/roomba_hack# roslaunch roomba_bringup bringup.launch
&lt;/code>&lt;/pre>
&lt;p>起動に成功すればルンバからピッと短い音が鳴り、ターミナルには赤い文字が出続けるはずです。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-7">
&lt;summary>開発PCでdockerコンテナを起動する&lt;/summary>
&lt;p>&lt;ol>
&lt;li>
&lt;p>開発PCでdockerコンテナを起動する&lt;/p>
&lt;pre>&lt;code class="language-sh">(開発PC):~$ cd ~/23_group_x/roomba_hack
(開発PC):~/23_group_x/roomba_hack$ ./RUN-DOCKER-CONTAINER.sh 192.168.10.7x
# xにはroomba_devの後につく数字を入れてください。
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>先ほどjetson内でdockerコンテナを起動しましたが、今回は開発PC内でコンテナを起動します。&lt;/li>
&lt;li>このとき引数にjetsonのIPアドレスを入れることで、jetson内のROSマスタ(前述)に、開発PCからアクセスできるようにしています。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>パッケージのビルド&lt;/p>
&lt;pre>&lt;code class="language-sh">(開発PC)(docker):~/roomba_hack# cd catkin_ws
(開発PC)(docker):~/roomba_hack/catkin_ws# ls
# catkin_ws内に存在するディレクトリを確認する。
(開発PC)(docker):~/roomba_hack/catkin_ws# catkin_make
# いろいろな出力が生成される。
(開発PC)(docker):~/roomba_hack/catkin_ws# ls
# 再度catkin_ws内に存在するディレクトリを確認する。
&lt;/code>&lt;/pre>
&lt;p>ここで、buildとdevelというディレクトリが生成されていると、うまくいっています。&lt;/p>
&lt;ul>
&lt;li>build&lt;br>
C++のコードを用いる際に、コンパイルされたファイルが生成されるディレクトリ。pythonを使っているときにはほとんど意識しない。&lt;/li>
&lt;li>devel&lt;br>
様々なファイルを含んでいるが、特にsetupファイルが重要。&lt;br>
このファイルを実行することで、現在いるワークスペースに含まれるコードを使用するようにROSの環境が設定される。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>setupファイルを実行する&lt;/p>
&lt;pre>&lt;code class="language-sh">(開発PC)(docker):~/roomba_hack/catkin_ws# source devel/setup.bash
# setupファイルを実行
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ol>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-8">
&lt;summary>コントローラーを使ってロボットを動かす&lt;/summary>
&lt;p>&lt;ul>
&lt;li>
&lt;p>コントローラーを起動&lt;br>
コントローラーが開発PCに接続されていることを確認してください。&lt;/p>
&lt;pre>&lt;code class="language-sh">(開発PC)(docker):~/roomba_hack/catkin_ws# roslaunch roomba_teleop teleop.launch
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>
&lt;p>コントローラのモード&lt;/p>
&lt;ul>
&lt;li>移動・停止&lt;/li>
&lt;li>自動・マニュアル&lt;/li>
&lt;li>ドッキング・アンドッキング&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>コントローラによる操縦&lt;/p>
&lt;ul>
&lt;li>移動ロック解除
L1を押している時のみ移動コマンドが動作します。&lt;/li>
&lt;li>左ジョイスティック
縦方向で前進速度(手前に倒すとバック)、横方向は回転速度に対応しています。&lt;/li>
&lt;li>左矢印
それぞれ、一定に低速度で前進・後退・回転します。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-9">
&lt;summary>Roombaの情報を取得する&lt;/summary>
&lt;p>&lt;ol>
&lt;li>
&lt;p>開発PCの新しいターミナルでdockerコンテナに入る&lt;/p>
&lt;p>bringup.launch及びteleop.launchを実行したターミナルは実行中のプログラムに占領されているので、開発PCで新しくターミナルを開いてコンテナの中に入ります。&lt;br>
すでに開発PCで起動されているコンテナに入る場合は、&lt;/p>
&lt;pre>&lt;code class="language-sh">(開発PC):~/23_group_x/roomba_hack$ docker exec -it roomba_hack bash
# docker exec -it &amp;lt;コンテナ名&amp;gt; bash で起動中のコンテナに入ることができる。
&lt;/code>&lt;/pre>
&lt;p>または&lt;/p>
&lt;pre>&lt;code class="language-sh">(開発PC):~/23_group_x/roomba_hack$ ./RUN-DOCKER-CONTAINER.sh
&lt;/code>&lt;/pre>
&lt;p>のいずれかのコマンドで入ることができます。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Roombaの情報を取得する&lt;/p>
&lt;p>さまざまなコマンドを使ってRoombaの情報を取得してみましょう。&lt;/p>
&lt;pre>&lt;code class="language-sh">(開発PC)(docker):~/roomba_hack# rosnode list
# ノードの一覧を表示する
(開発PC)(docker):~/roomba_hack# rostopic list
# トピックの一覧を表示する
(開発PC)(docker):~/roomba_hack# rostopic echo /cmd_vel
# /cmd_velというトピックの中身を表示する
# teleop.launchを実行している状態でコントローラーを操作すると、/cmd_velの中身が変化することがわかる。
(開発PC)(docker):~/roomba_hack# rqt_graph
# ノードとトピックの関係を表示
(開発PC)(docker):~/roomba_hack# rviz
# rvizを起動
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ol>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-10">
&lt;summary>プロセスの終了・dockerコンテナから出る&lt;/summary>
&lt;p>&lt;ol>
&lt;li>
&lt;p>プロセスの終了&lt;br>
一部のプログラムは終了するまで処理を続けるため、明示的に終了させる必要があります。&lt;/p>
&lt;p>多くのプログラムは&lt;code>Ctrl+C&lt;/code>で終了します。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>dockerコンテナ・ターミナルから出る&lt;/p>
&lt;p>コマンドライン上で&lt;/p>
&lt;pre>&lt;code class="language-shell">exit
&lt;/code>&lt;/pre>
&lt;p>を実行することで、&lt;/p>
&lt;ul>
&lt;li>コンテナの中にいる場合はコンテナ外にでる。&lt;/li>
&lt;li>sshしている場合はsshを終了する。&lt;/li>
&lt;li>ターミナルを使用している場合はターミナルを終了する。&lt;/li>
&lt;/ul>
&lt;p>ことができます。また、&lt;code>Ctrl+D&lt;/code>でも同様のことができます。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/p>
&lt;/details></description></item><item><title>ROSのパッケージ・ワークスペース</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap2/rosbasic/</link><pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap2/rosbasic/</guid><description>&lt;p>ROSのパッケージ管理について理解しよう&lt;/p>
&lt;h2 id="learn">Learn&lt;/h2>
&lt;h3 id="rosのパッケージ">ROSのパッケージ&lt;/h3>
&lt;p>ROSでは、特定の機能やタスクを実現するためのコードやファイルをまとめてパッケージとして管理します。
各パッケージは独立して開発・保守され、他のパッケージと組み合わせて使用することができます。また、各パッケージが独立していることで、一度開発した機能を他のプロジェクトで再利用することも容易になります。&lt;/p>
&lt;p>例として、navigation_tutorialパッケージのファイル構成を示します。&lt;/p>
&lt;pre>&lt;code>navigation_tutorial
   ├── CMakeLists.txt
   ├── launch
   │   ├── amcl.launch
   │   ├── avoidance.launch
   │   ├── gmapping.launch
   │   ├── go_straight.launch
   │   ├── localization.launch
   │   ├── map_server.launch
   │   ├── move_base.launch
   │   └── navigation.launch
   ├── package.xml
   ├── params
   │   ├── base_global_planner_params.yaml
   │   ├── base_local_planner_params.yaml
   │   ├── costmap_common_params.yaml
   │   ├── dwa_local_planner_params.yaml
   │   ├── global_costmap_params.yaml
   │   ├── local_costmap_params.yaml
   │   └── move_base_params.yaml
   ├── scripts
   │   ├── avoidance.py
   │   ├── simple_control2.py
   │   └── simple_control.py
   └── src
   ├── avoidance.cpp
   └── go_straight.cpp
&lt;/code>&lt;/pre>
&lt;details class="spoiler " id="spoiler-0">
&lt;summary>scriptsディレクトリ、srcディレクトリの役割&lt;/summary>
&lt;p>&lt;p>一般的に、&lt;code>scripts&lt;/code>ディレクトリ内にpythonのプログラムが、&lt;code>src&lt;/code>ディレクトリ内にC++のプログラムが配置されます。&lt;/p>
&lt;p>作成したプログラムは&lt;code>rosrun&lt;/code>コマンドで実行することができます。&lt;/p>
&lt;pre>&lt;code class="language-shell">$ rosrun &amp;lt;package name&amp;gt; &amp;lt;file name&amp;gt;
# pythonファイルの場合
$ rosrun navigation_tutorial simple_control2.py
# C++ファイルの場合
$ rosrun navigation_tutorial go_straight
&lt;/code>&lt;/pre>
&lt;p>実行時にパッケージ名を指定するので、現在どこのディレクトリにいるかに関係なく実行が可能です。&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-1">
&lt;summary>launchディレクトリの役割&lt;/summary>
&lt;p>&lt;p>&lt;code>launch&lt;/code>ディレクトリにはlaunchファイルが配置されています。&lt;br>
launchファイルは複数のROSノードを一括で起動するための設定が書かれたファイルです。複数のノードを起動したい時に、必要なファイルを一つ一つコマンドラインで実行していくことは大変ですが、launchファイルを用いることで一括で起動することができます。&lt;/p>
&lt;p>launchファイルは&lt;code>roslaunch&lt;/code>コマンドで実行することができます。&lt;/p>
&lt;pre>&lt;code class="language-shell">$ roslaunch &amp;lt;package name&amp;gt; &amp;lt;launch file name&amp;gt;
# 例
$ roslaunch navigation_tutorial move_base.launch
&lt;/code>&lt;/pre>
&lt;p>.pyファイルや.cppファイルと同様、実行時にパッケージを指定するので、現在どこのディレクトリにいるかに関係なく実行が可能です。&lt;/p>
&lt;/p>
&lt;/details>
&lt;h3 id="rosのワークスペース">ROSのワークスペース&lt;/h3>
&lt;p>新しいROSのパッケージの開発は、一般にワークスペースと呼ばれる作業スペースのもとで行われます。&lt;br>
ワークスペースは、パッケージのビルドや実行に必要なファイルをまとめて管理するためのディレクトリです。&lt;code>catkin_make&lt;/code>コマンドを実行することで作成することができます。ワークスペースのディレクトリ名は任意ですが、よく&lt;code>catkin_ws&lt;/code>という名前が使われます。&lt;/p>
&lt;p>roomba_hackリポジトリ下にあるcatkin_wsのファイル構成を示します。&lt;/p>
&lt;pre>&lt;code>catkin_ws
   ├── build
   ├── devel
   └── src
   ├── CMakeLists.txt
   ├── navigation_tutorial
   │   ├── CMakeLists.txt
   │   ├── launch
   │   ├── package.xml
   │   ├── params
   │   ├── scripts
   │   └── src
   └── roomba
   ├── roomba_bringup
   │   ├── CMakeLists.txt
   │   ├── config
   │   ├── launch
   │   └── package.xml
   ├── roomba_description
   │   ├── CMakeLists.txt
   │   ├── config
   │   ├── launch
   │   ├── meshes
   │   ├── package.xml
   │   └── urdf
   ├── roomba_gazebo
   │   ├── CMakeLists.txt
   │   ├── launch
   │   └── package.xml
   └── roomba_teleop
   ├── CMakeLists.txt
   ├── include
   ├── launch
   ├── package.xml
   └── src
&lt;/code>&lt;/pre>
&lt;p>catkin_ws内でよく使用される&lt;code>catkin_make&lt;/code>コマンドについて説明します。&lt;/p>
&lt;pre>&lt;code class="language-shell">$ cd catkin_ws # catkin_wsに移動
$ catkin_make
&lt;/code>&lt;/pre>
&lt;p>のように使用します。この時、以下の手順が実行されています。&lt;/p>
&lt;ol>
&lt;li>ワークスペースのsrcディレクトリ内に配置されたROSパッケージを検出し、ビルド対象として認識する。&lt;/li>
&lt;li>各パッケージの依存関係を解決し、ビルドが必要な場合はコンパイルを行う。&lt;/li>
&lt;li>ビルドが完了したパッケージをdevelディレクトリに配置する。&lt;/li>
&lt;/ol>
&lt;p>また、&lt;code>catkin_make&lt;/code>コマンドの実行後に&lt;/p>
&lt;pre>&lt;code class="language-shell">$ source devel/setup.bash
&lt;/code>&lt;/pre>
&lt;p>を実行することで環境変数に自分が今いるワークスペースのパスを追加することができます。&lt;br>
これにより、ワークスペース内のパッケージを使用できるようになります。&lt;/p>
&lt;!--
catkin_wsのsrc内でパッケージ作成を行い、catkin_ws直下で`catkin_make`コマンドを実行すると、Cプログラムのビルドが行われ、buildディレクトリとdevelディレクトリが作成されます。
作成されたdevelディレクトリの中のsetup.bashをソース
```
$ source devel/setup.bash
```
することで、ワークスペース内のパッケージのパスを通すことができます。　
パッケージのパスを通すことで、ROSのパッケージに関するコマンドの使用や、プログラムの実行（`rosrun`, `roslaunch`）ができるようになります。
-->
&lt;h3 id="rosのコマンド">ROSのコマンド&lt;/h3>
&lt;p>ROSのコマンドのうち、よく使用するものを紹介します。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Topic関連&lt;/p>
&lt;pre>&lt;code>$ rostopic list 　　　　　　 topicの一覧を表示する
$ rostopic echo &amp;lt;topic name&amp;gt; 　 　　　　　 指定されたtopicの中身を表示する
$ rostopic hz &amp;lt;topic name&amp;gt; 　　　　　　　 topicの配信周波数を取得する
$ rostopic info &amp;lt;topic name&amp;gt; 　　　　　　　 topicの情報を表示する
$ rostopic pub &amp;lt;topic name&amp;gt; &amp;lt;topic&amp;gt; 　 　topicを配信する
$ rostopic type &amp;lt;topic name&amp;gt; topicの型を確認する
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Node関連&lt;/p>
&lt;pre>&lt;code>$ rosnode list nodeの一覧を表示する
$ rosnode ping &amp;lt;node name&amp;gt; nodeの接続テストを行う
$ rosnode info &amp;lt;node name&amp;gt; nodeの情報を表示する
$ rosnode kill &amp;lt;node name&amp;gt; nodeをシャットダウンする
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Package関連&lt;/p>
&lt;pre>&lt;code>$ rospack list packageの一覧を表示する
$ roscd &amp;lt;package name&amp;gt; 指定したpackage内に移動する
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;h3 id="rosのプログラムの書き方">ROSのプログラムの書き方&lt;/h3>
&lt;p>それでは実際にプログラム例を見てみましょう。&lt;/p>
&lt;pre>&lt;code class="language-python:simple_control.py">#!/usr/bin/env python3
import rospy
from geometry_msgs.msg import Twist
def time_control(pub, velocity, yawrate, time): # (2)
vel = Twist()
start_time = rospy.get_rostime().secs
while(rospy.get_rostime().secs-start_time&amp;lt;time):
vel.linear.x = velocity
vel.angular.z = yawrate
pub.publish(vel)
rospy.sleep(0.1)
def simple_controller(): # (1)
rospy.init_node('simple_controller', anonymous=True)
pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)
time_control(pub, 0.0, 0.0, 0.5)
time_control(pub, 0.3, 0.0, 2.0)
time_control(pub, 0.0, 0.0, 0.5)
time_control(pub, -0.3, 0.0, 2.0)
time_control(pub, 0.0, 0.0, 0.5)
time_control(pub, 0.0, 0.5, 2.0)
time_control(pub, 0.0, 0.0, 0.5)
time_control(pub, 0.0, -0.5, 2.0)
if __name__=='__main__': # (3)
try:
simple_controller()
except rospy.ROSInitException:
pass
&lt;/code>&lt;/pre>
&lt;details class="spoiler " id="spoiler-2">
&lt;summary>(1) simple_controller関数&lt;/summary>
&lt;p>&lt;p>まずsimple_controller関数内をみていきましょう。&lt;br>
以下の部分で&amp;quot;simple_controller&amp;quot;という名前のノードを定義しています。&lt;/p>
&lt;pre>&lt;code class="language-python">rospy.init_node('simple_controller', anonymous=True)
&lt;/code>&lt;/pre>
&lt;p>以下の部分で、このノードがPublisherであることを宣言しています。&lt;/p>
&lt;pre>&lt;code class="language-python">pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10)
&lt;/code>&lt;/pre>
&lt;p>今回の場合は、&lt;code>/cmd_vel&lt;/code>トピックを&lt;code>Twist&lt;/code>型で送信するPublisherを宣言しています。&lt;/p>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-3">
&lt;summary>(2) time_control関数&lt;/summary>
&lt;p>&lt;p>続いて、time_control関数です。&lt;/p>
&lt;p>この関数はpublisher、速度、角速度、時間を受け取り、速度指令をpublishします。&lt;/p>
&lt;pre>&lt;code class="language-python">def time_control(pub, velocity, yawrate, time):
vel = Twist()
start_time = rospy.get_rostime().secs
while(rospy.get_rostime().secs-start_time&amp;lt;time):
vel.linear.x = velocity
vel.angular.z = yawrate
pub.publish(vel)
rospy.sleep(0.1)
&lt;/code>&lt;/pre>
&lt;p>ここでTwist型のインスタンスを作成しています。&lt;/p>
&lt;pre>&lt;code class="language-python"> vel = Twist()
&lt;/code>&lt;/pre>
&lt;p>while文で受け取った時間が過ぎるまでの間、受け取った速度と各速度をvelに格納し、&lt;code>pub.publish(vel)&lt;/code>でpublishを行なっています。&lt;/p>
&lt;pre>&lt;code class="language-python"> while(rospy.get_rostime().secs-start_time&amp;lt;time):
vel.linear.x = velocity
vel.angular.z = yawrate
pub.publish(vel)
rospy.sleep(0.1)
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-4">
&lt;summary>(3) グローバル変数__name__を用いたファイルの実行&lt;/summary>
&lt;p>&lt;p>(1)や(2)は関数の定義をしているだけで、実際にプログラムを実行した際には&lt;/p>
&lt;pre>&lt;code class="language-python">if __name__=='__main__':
&lt;/code>&lt;/pre>
&lt;p>以下の部分が実行されます。&lt;/p>
&lt;p>__name__はpythonの特殊な変数の一つで、ファイル実行時に自動で設定されます。
pythonのプログラムはコマンドで直接実行するか、importで他のプログラムから参照されるかのいずれかの方法により実行されますが、__name__はこの実行方法によって値が変わります。&lt;/p>
&lt;ul>
&lt;li>直接実行された場合、__name__には&lt;code>__main__&lt;/code>と言う文字列が代入されます。&lt;/li>
&lt;li>importされた場合、__name__にはファイル名が代入されます。&lt;/li>
&lt;/ul>
&lt;p>この性質を利用し、ファイルが直接実行された場合のみ実行したい処理をif文で囲んでいます。&lt;br>
大抵の場合、rosのプログラムでは、上に挙げたファイルのように、関数やクラスの定義と実際にプログラムを実行する部分を分けて記述します。&lt;/p>
&lt;/p>
&lt;/details>
&lt;h2 id="演習">演習&lt;/h2>
&lt;details class="spoiler " id="spoiler-5">
&lt;summary>【jetson・開発マシン】それぞれdockerコンテナを起動&lt;/summary>
&lt;p>&lt;p>jetsonでdockerコンテナを起動&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC):~$ ssh roomba_dev1
(jetson):~$ cd ~/group_a/roomba_hack
(jetson):~/group_a/roomba_hack ./RUN-DOCKER-CONTAINER.sh
(jetson)(docker):~/roomba_hack#
&lt;/code>&lt;/pre>
&lt;p>開発PCでdockerコンテナを起動&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC):~$ cd ~/group_a/roomba_hack
(開発PC):~/group_a/roomba_hack# ./RUN-DOCKER-CONTAINER.sh 192.168.10.7x
(開発PC)(docker):~/roomba_hack#
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-6">
&lt;summary>【jetson・開発マシン】ビルドをしてパスを通す&lt;/summary>
&lt;p>&lt;p>catkin_make後に&lt;code>devel&lt;/code>と&lt;code>build&lt;/code>ディレクトリが作成されることを確認しましょう。&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker):~/roomba_hack# cd catkin_ws
(開発PC)(docker):~/roomba_hack/catkin_ws# rm -rf devel build
(開発PC)(docker):~/roomba_hack/catkin_ws# ls
(開発PC)(docker):~/roomba_hack/catkin_ws# catkin_make
(開発PC)(docker):~/roomba_hack/catkin_ws# ls
(開発PC)(docker):~/roomba_hack/catkin_ws# source ./devel/setup.bash
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-7">
&lt;summary>【jetson】ROSマスタ、各種ノードを起動&lt;/summary>
&lt;p>&lt;pre>&lt;code class="language-shell">(jetson)(docker):~/roomba_hack# roslaunch roomba_bringup bringup.launch
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;h3 id="rosメッセージの可視化">ROSメッセージの可視化&lt;/h3>
&lt;details class="spoiler " id="spoiler-8">
&lt;summary>【開発PC】topicの確認&lt;/summary>
&lt;p>&lt;p>Topic関連のコマンドのところの&lt;code>rostopic list&lt;/code>コマンドを使用してtopic一覧を表示してみましょう&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker):~/roomba_hack# rostopic list
&lt;/code>&lt;/pre>
&lt;p>特定のtopicの型を確認&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker)# rostopic type /camera/color/image_raw
(開発PC)(docker)# rostopic type /scan
&lt;/code>&lt;/pre>
&lt;p>その型が実際にどのような構成をしているのかは&lt;code>rosmsg info &amp;lt;topic type&amp;gt;&lt;/code>で調べられます。&lt;/p>
&lt;p>参考&lt;/p>
&lt;p>sensor_msgs/LaserScan型 &lt;a href="http://docs.ros.org/en/melodic/api/sensor_msgs/html/msg/LaserScan.html">http://docs.ros.org/en/melodic/api/sensor_msgs/html/msg/LaserScan.html&lt;/a>&lt;/p>
&lt;p>sensor_msgs/Image型 &lt;a href="http://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/Image.html">http://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/Image.html&lt;/a>&lt;/p>
&lt;p>特定のtopicの中身を確認&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker)# rostopic echo /camera/color/image_raw
(開発PC)(docker)# rostopic echo /scan
&lt;/code>&lt;/pre>
&lt;p>rvizを用いて可視化&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker)# rviz
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-9">
&lt;summary>【開発PC】topicのpublish(配信)&lt;/summary>
&lt;p>&lt;p>topic&lt;code>/cmd_vel&lt;/code>の情報を確認&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker)# rostopic info /cmd_vel
&lt;/code>&lt;/pre>
&lt;p>topic&lt;code>/cmd_vel&lt;/code>の型を確認&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker)# rostopic type /cmd_vel
&lt;/code>&lt;/pre>
&lt;p>geometry_msgs/Twist型 &lt;a href="http://docs.ros.org/en/noetic/api/geometry_msgs/html/msg/Twist.html">http://docs.ros.org/en/noetic/api/geometry_msgs/html/msg/Twist.html&lt;/a>&lt;/p>
&lt;p>topic&lt;code>/cmd_vel&lt;/code>をpublish&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker)# rostopic pub /cmd_vel geometry_msgs/Twist &amp;quot;linear:
x: 1.0
y: 0.0
z: 0.0
angular:
x: 0.0
y: 0.0
z: 0.0&amp;quot;
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-shell">(開発PC)(docker)# rosrun navigation_tutorial simple_control.py
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;details class="spoiler " id="spoiler-10">
&lt;summary>Try it! 時間が余った人向け&lt;/summary>
&lt;p>&lt;p>try it! &lt;code>roomba_bringup&lt;/code>パッケージの&lt;code>bringup.launch&lt;/code>の中身を読んでみよう&lt;/p>
&lt;p>hint roscdコマンドを使うとパッケージへ簡単に移動ができます。ファイルの中身を表示するには&lt;code>cat&lt;/code>コマンドを使用します。&lt;/p>
&lt;p>try it! 開発PCで&lt;code>rosnode&lt;/code>関連のコマンドを使ってみよう&lt;/p>
&lt;p>try it! 開発PCで&lt;code>rosrun rqt_graph rqt_graph&lt;/code>を実行してnodeとtopicの関連を可視化してみよう&lt;/p>
&lt;p>try it! 開発PCで&lt;code>simple_control.py&lt;/code>の中身を読んでコードを変更してみよう&lt;/p>
&lt;p>hint コードを編集するときはエディタを使うことがおすすめです。新しくターミナルを開いて&lt;/p>
&lt;pre>&lt;code class="language-shell">(開発PC):~$ cd group_a/roomba_hack
(開発PC):~group_a/roomba_hack$ code .
&lt;/code>&lt;/pre>
&lt;p>でVScodeを起動することができます。&lt;/p>
&lt;/p>
&lt;/details></description></item><item><title>ロボットシステムにおけるセンシング・アクチュエーション・通信①</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap2/sensing1/</link><pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap2/sensing1/</guid><description>&lt;p>センサの値を読み取りロボットを動かしてみよう&lt;/p>
&lt;h2 id="learn">Learn&lt;/h2>
&lt;h3 id="ロボットセンサの基礎知識">ロボットセンサの基礎知識&lt;/h3>
&lt;p>ロボットが動作するために必要なセンサは大きく2種類に分けられる。&lt;/p>
&lt;p>1つ目が外界センサで、これはロボットが行動する環境の情報を取得するためのセンサーである。
具体的なセンサとして、&lt;/p>
&lt;ul>
&lt;li>レーザスキャナ
&lt;ul>
&lt;li>レーザービームを照射して物体上の点までの距離と方向を計測する。レーザビームを走査することで、センサ周囲の広い範囲を計測した点群を得られる。&lt;/li>
&lt;li>レーザスキャナを用いて対象物までの距離や位置、形状を検知することをLiDAR(Light Detection And Ranging(光による検知と測距))という。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>デプスカメラ
&lt;ul>
&lt;li>赤外線などを発光して距離情報を画像として計測する。それと同時に通常のRGB画像も取得できるものがある。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>などがあげられる。&lt;/p>
&lt;p>センサのノイズの影響を軽減するため、複数のセンサを組み合わせて利用されることもある。&lt;/p>
&lt;p>2つ目は内界センサで、これは(ロボットアームのような変形可能な)ロボットが自身の内部状態を把握し、位置や姿勢を制御するために使われるセンサーである。&lt;/p>
&lt;ul>
&lt;li>ホイールエンコーダ
&lt;ul>
&lt;li>回転信号を電気信号に変換するデバイス。&lt;/li>
&lt;li>ロボットの位置の推定：台車に取り付けられたホイールエンコーダが回転角度や回転速度を計測し、ロボットの位置や向きを推定する。&lt;/li>
&lt;li>ロボットアームの制御：ロボットアームは、ベースや関節にモーターとホイールエンコーダを備えている。ホイールエンコーダは関節の回転角度を計測し、アームの位置制御に使用される。これにより、アームは所望の位置や角度に正確に移動することができる。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>IMU(Internal Measurement Unit)
&lt;ul>
&lt;li>ジャイロ、加速度センサ、磁気センサなどが一体となったもの。
&lt;ul>
&lt;li>ジャイロセンサは回転角・各速度を求めるセンサ。&lt;/li>
&lt;li>加速度センサは衝撃の検出、歩行ロボットの姿勢制御などに使われる。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>などが内界センサである。&lt;/p>
&lt;p>参考&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.jsme.or.jp/jsme-medwiki/14:1013897#:~:text=robot%20sensor">https://www.jsme.or.jp/jsme-medwiki/14:1013897#:~:text=robot%20sensor&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>ナビゲーション</title><link>https://matsuolab.github.io/roomba_hack_course/course/chap4/navigation/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/course/chap4/navigation/</guid><description>&lt;h2 id="learn">Learn&lt;/h2>
&lt;h3 id="navigationシステム">Navigationシステム&lt;/h3>
&lt;p>ナビゲーションの目的は、地図上の任意の目標地点へ、障害物を避けながらなるべく早く自律して移動することです。&lt;/p>
&lt;p>ナビゲーションシステムの出力はロボットへの行動指令値(速度など)ですが、入力は以下の4つになります。&lt;/p>
&lt;ul>
&lt;li>地図&lt;/li>
&lt;li>目標位置&lt;/li>
&lt;li>自己位置推定結果&lt;/li>
&lt;li>リアルタイムのセンサ情報(LiDARスキャン情報など)&lt;/li>
&lt;/ul>
&lt;p>ナビゲーションでは、地図全体とロボット周辺(センサで見える範囲)の大きく2つに分けて考えることが多いです。&lt;/p>
&lt;p>地図全体を考えるグローバルパスプランでは、地図情報とゴール情報から大まかなゴールまでの経路を算出します。&lt;/p>
&lt;p>ロボット周辺を考える ローカルパスプランでは、グローバルで算出した経路に沿うようにしつつ、周辺の障害物情報を避ける行動指令値を算出します。&lt;/p>
&lt;p>それぞれの経路を考えるにあたって、経路のコストがどうなるか重要になります。
このコストを表現する方法として、コストマップが用いられることが多いです。&lt;/p>
&lt;figure id="figure-navigationシステム概要from-ros-wikihttpswikirosorgmove_base">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../overview_tf_small.png" alt="Navigationシステム概要(from [ROS wiki](https://wiki.ros.org/move_base))" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
Navigationシステム概要(from &lt;a href="https://wiki.ros.org/move_base">ROS wiki&lt;/a>)
&lt;/figcaption>&lt;/figure>
&lt;h3 id="cost-map">Cost Map&lt;/h3>
&lt;p>コストマップは、経路を算出するために用いることから、扱いやすいグリット上の占有格子地図という形で表現されることが多いです。&lt;/p>
&lt;p>(空を飛んだり、3次元地形を考えなくていい場合は、基本2次元で表現します。)&lt;/p>
&lt;p>経路は格子地図上で、点で扱うことが多いですが、ロボット自身はある程度の大きさを持っているので、スキャン情報で得られた点ギリギリに経路を生成すると、衝突してしまします。&lt;/p>
&lt;p>そのため、コストマップでは以下の図のようにスキャンで得られた点(図中の赤点)から、ロボットが入ってほしくない範囲にコスト(図中の青く塗りつぶされているところ)が付与するという表現をします。&lt;/p>
&lt;figure id="figure-コストマップ概要from-ros-wikihttpswikirosorgcostmap_2d">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../costmap_rviz.png" alt="コストマップ概要(from [ROS wiki](https://wiki.ros.org/costmap_2d))" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
コストマップ概要(from &lt;a href="https://wiki.ros.org/costmap_2d">ROS wiki&lt;/a>)
&lt;/figcaption>&lt;/figure>
&lt;h3 id="global-path-planning">Global Path Planning&lt;/h3>
&lt;p>グローバルパスプランの例として、グラフ探索を利用したダイクストラ法やA*法などで経路探索をすることがあります。&lt;/p>
&lt;figure id="figure-グローバルパスプランの例from-pythonroboticshttpsgithubcomatsushisakaipythonrobotics">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../astar.gif" alt="グローバルパスプランの例(from [PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics))" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
グローバルパスプランの例(from &lt;a href="https://github.com/AtsushiSakai/PythonRobotics">PythonRobotics&lt;/a>)
&lt;/figcaption>&lt;/figure>
&lt;h3 id="local-path-planning">Local Path Planning&lt;/h3>
&lt;p>局所経路計画(Local Path Planning)は、ロボット周辺の障害物を避けながら、目標値へ早く行けるような経路(ロボットの行動)を算出するモジュールです。&lt;/p>
&lt;p>代表的なアルゴリズムとしてDynamic Window Approach(DWA)というものがあります。
&lt;figure id="figure-ローカルパスプラン概要from-ros-wikihttpswikirosorgbase_local_planner">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="../local_plan.png" alt="ローカルパスプラン概要(from [ROS wiki](https://wiki.ros.org/base_local_planner))" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
ローカルパスプラン概要(from &lt;a href="https://wiki.ros.org/base_local_planner">ROS wiki&lt;/a>)
&lt;/figcaption>&lt;/figure>&lt;/p>
&lt;p>アルゴリズムの概要は以下になります。&lt;/p>
&lt;ol>
&lt;li>ロボットの行動空間から行動をサンプル&lt;/li>
&lt;li>サンプルした行動とロボットの運動モデルを用いて、一定時間シミュレーションをして経路を生成&lt;/li>
&lt;li>生成した経路ごとに、コストマップやゴール情報からコストを算出&lt;/li>
&lt;li>コスト最小の経路を選択し、ロボットの指令値とする&lt;/li>
&lt;li>1~4を繰り返す&lt;/li>
&lt;/ol>
&lt;h2 id="演習">演習&lt;/h2>
&lt;!-- &lt;details class="spoiler " id="spoiler-4">
&lt;summary>Dockerfileにnavigationを追加してBuildする&lt;/summary>
&lt;p>&lt;/p>
&lt;/details> -->
&lt;details class="spoiler " id="spoiler-5">
&lt;summary>navigationをlaunchして、rviz上で指定した位置までナビゲーションさせてみる&lt;/summary>
&lt;p>&lt;pre>&lt;code>(開発PC)(docker) roslaunch navigation_tutorial navigation.launch
&lt;/code>&lt;/pre>
&lt;/p>
&lt;/details>
&lt;!-- &lt;details class="spoiler " id="spoiler-6">
&lt;summary>navigationをlaunchして、map座標系の位置を指定してナビゲーションさせてみる&lt;/summary>
&lt;p>&lt;/p>
&lt;/details> -->
&lt;details class="spoiler " id="spoiler-7">
&lt;summary>navigationのparamをチューニングする&lt;/summary>
&lt;p>&lt;p>move baseのパラメータは &lt;code>navigation_tutorial/params&lt;/code> の中にyaml形式で保存されています。&lt;/p>
&lt;p>launchファイルではloadコマンドでyamlを読み込んでいます。&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://wiki.ros.org/move_base#Parameters">move_base&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://wiki.ros.org/base_local_planner#Parameters">base_local_planner&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://wiki.ros.org/costmap_2d#costmap_2d.2Flayered.Parameters">costmap_2d&lt;/a>&lt;/li>
&lt;/ul>
&lt;/p>
&lt;/details></description></item><item><title>Jian Yang and Monica Hall Win the Best Paper Award at Wowchemy 2020</title><link>https://matsuolab.github.io/roomba_hack_course/post/20-12-02-icml-best-paper/</link><pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/post/20-12-02-icml-best-paper/</guid><description>&lt;p>Congratulations to Jian Yang and Monica Hall for winning the Best Paper Award at the 2020 Conference on Wowchemy for their paper “Learning Wowchemy”.&lt;/p>
&lt;p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer tempus augue non tempor egestas. Proin nisl nunc, dignissim in accumsan dapibus, auctor ullamcorper neque. Quisque at elit felis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget elementum odio. Cras interdum eget risus sit amet aliquet. In volutpat, nisl ut fringilla dignissim, arcu nisl suscipit ante, at accumsan sapien nisl eu eros.&lt;/p>
&lt;p>Sed eu dui nec ligula bibendum dapibus. Nullam imperdiet auctor tortor, vel cursus mauris malesuada non. Quisque ultrices euismod dapibus. Aenean sed gravida risus. Sed nisi tortor, vulputate nec quam non, placerat porta nisl. Nunc varius lobortis urna, condimentum facilisis ipsum molestie eu. Ut molestie eleifend ligula sed dignissim. Duis ut tellus turpis. Praesent tincidunt, nunc sed congue malesuada, mauris enim maximus massa, eget interdum turpis urna et ante. Morbi sem nisl, cursus quis mollis et, interdum luctus augue. Aliquam laoreet, leo et accumsan tincidunt, libero neque aliquet lectus, a ultricies lorem mi a orci.&lt;/p>
&lt;p>Mauris dapibus sem vel magna convallis laoreet. Donec in venenatis urna, vitae sodales odio. Praesent tortor diam, varius non luctus nec, bibendum vel est. Quisque id sem enim. Maecenas at est leo. Vestibulum tristique pellentesque ex, blandit placerat nunc eleifend sit amet. Fusce eget lectus bibendum, accumsan mi quis, luctus sem. Etiam vitae nulla scelerisque, eleifend odio in, euismod quam. Etiam porta ullamcorper massa, vitae gravida turpis euismod quis. Mauris sodales sem ac ultrices viverra. In placerat ultrices sapien. Suspendisse eu arcu hendrerit, luctus tortor cursus, maximus dolor. Proin et velit et quam gravida dapibus. Donec blandit justo ut consequat tristique.&lt;/p></description></item><item><title>Richard Hendricks Wins First Place in the Wowchemy Prize</title><link>https://matsuolab.github.io/roomba_hack_course/post/20-12-01-wowchemy-prize/</link><pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/post/20-12-01-wowchemy-prize/</guid><description>&lt;p>Congratulations to Richard Hendricks for winning first place in the Wowchemy Prize.&lt;/p>
&lt;p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer tempus augue non tempor egestas. Proin nisl nunc, dignissim in accumsan dapibus, auctor ullamcorper neque. Quisque at elit felis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget elementum odio. Cras interdum eget risus sit amet aliquet. In volutpat, nisl ut fringilla dignissim, arcu nisl suscipit ante, at accumsan sapien nisl eu eros.&lt;/p>
&lt;p>Sed eu dui nec ligula bibendum dapibus. Nullam imperdiet auctor tortor, vel cursus mauris malesuada non. Quisque ultrices euismod dapibus. Aenean sed gravida risus. Sed nisi tortor, vulputate nec quam non, placerat porta nisl. Nunc varius lobortis urna, condimentum facilisis ipsum molestie eu. Ut molestie eleifend ligula sed dignissim. Duis ut tellus turpis. Praesent tincidunt, nunc sed congue malesuada, mauris enim maximus massa, eget interdum turpis urna et ante. Morbi sem nisl, cursus quis mollis et, interdum luctus augue. Aliquam laoreet, leo et accumsan tincidunt, libero neque aliquet lectus, a ultricies lorem mi a orci.&lt;/p>
&lt;p>Mauris dapibus sem vel magna convallis laoreet. Donec in venenatis urna, vitae sodales odio. Praesent tortor diam, varius non luctus nec, bibendum vel est. Quisque id sem enim. Maecenas at est leo. Vestibulum tristique pellentesque ex, blandit placerat nunc eleifend sit amet. Fusce eget lectus bibendum, accumsan mi quis, luctus sem. Etiam vitae nulla scelerisque, eleifend odio in, euismod quam. Etiam porta ullamcorper massa, vitae gravida turpis euismod quis. Mauris sodales sem ac ultrices viverra. In placerat ultrices sapien. Suspendisse eu arcu hendrerit, luctus tortor cursus, maximus dolor. Proin et velit et quam gravida dapibus. Donec blandit justo ut consequat tristique.&lt;/p></description></item><item><title/><link>https://matsuolab.github.io/roomba_hack_course/admin/config.yml</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/admin/config.yml</guid><description/></item><item><title/><link>https://matsuolab.github.io/roomba_hack_course/contact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://matsuolab.github.io/roomba_hack_course/contact/</guid><description/></item></channel></rss>